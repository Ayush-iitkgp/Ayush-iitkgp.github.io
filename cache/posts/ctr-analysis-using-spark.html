<h1>Introduction</h1>
<p>In recent years, programmatic advertising is been taking over the online advertisement industry. To enable automatic selling and purchasing ad impressions between advertisers and publishers through real-time auctions, Real-Time Bidding (RTB) is quickly becoming the leading method.</p>
<p>In contrast to the traditional online ad market, where a certain amount of impressions is sold at a fixed rate, RTB allows advertisers to bid each impression individually in real time at a cost based on impression-level features. Real-time Bidding (RTB) is a way of transacting media that allows an individual ad impression to be put up for bid in real-time. This is done through a programmatic <strong>on-the-spot auction</strong>, which is similar to how financial markets operate. RTB allows for Addressable Advertising; the ability to serve ads to consumers directly based on their demographic, psychographic, or behavioral attributes.</p>
<p>Many DSPs (Demand Side Platforms) act as agents for the advertisers and take part in the real-time auction on behalf of them. In order to enable real-time bidding and provide the advertisers with the clicks at the lowest price possible, DSPs develop their own machine learning algorithms using techniques such as <a href="https://en.wikipedia.org/wiki/Feature_hashing">hashing trick</a>, feature combinations, stochastic gradient descent etc.</p>
<h1>Motivation</h1>
<p>Like the standard practice in most of the data science use cases, whenever a new algorithm is developed, they are put into A/B test against the already existing algorithm in the production (at least for few days) in order to do determine which algorithm suits the business metrics better. </p>
<p>Due to the huge volume of bid requests (around a million bid requests per second), the amount of data collected during AB is in the order of 100 GBs. Python's Pandas library has basically all the functionality needed to do the offline analysis of the data collected in terms of CPCs, spend, clicks, CTR, AUC etc. </p>
<p>But, Pandas has a huge problem, it has to load all the dataset in memory in order to run some computations on it. From my experience, <strong>Pandas needs the RAM size to be 3 times the size of the dataset</strong> and it can not be run into a distributed environment as cluster a of machines. This is where <a href="https://spark.apache.org/">Apache Spark</a> is useful as it can process the datasets whose size is more than the size of the RAM. This blog will not cover the internals of Apache Spark and how it works rather I will jump to how the Pandas CTR Analysis code can be easily converted into spark analysis with few syntax changes.</p>
<h1>Migrating to Spark from Pandas</h1>
<p>In new versions, Spark started to support Dataframes which is conceptually equivalent to a dataframe in R/Python. Dataframe support in Spark has made it comparatively easy for users to switch to Spark from Pandas using a very similar syntax. In this section, I would jump to coding and show how the CTR analysis that is done in Pandas can be migrated to Spark. </p>
<p>Before I jump into the coding, I would like to introduce some of the keywords used in the code:</p>
<p><em>Effective CPC</em>: Total money spent / Total number of clicks</p>
<p><em>Label</em>: It is either 0 or 1 (1 signifies that the click happened and 0 is for no click)</p>
<p><em>Win Price</em>: The price paid to win the on-spot auction</p>
<p><em>Bid CPC</em>: The price the advertiser is willing to pay for the impression</p>
<p><em>CTR</em>: Click Through Rate = Total Number of Clicks / Total Number of Impressions</p>
<p><strong>How is Win Price different from Bid Price?</strong></p>
<p>If an exchange is using <a href="https://en.wikipedia.org/wiki/First-price_sealed-bid_auction">First Price Auction</a>, the win pice and the bid price is same but if the exchange is using <a href="https://en.wikipedia.org/wiki/Generalized_second-price_auction">Second Price Auction</a>, the advertizer with the highest bid price wins but it pays the price equivalent to the second highest bid price hence the win price is less than the bid price.</p>
<h2><strong>Setting up notebook and importing libraries</strong></h2>
<h4><strong>Pandas</strong></h4>
<div class="code"><pre class="code literal-block"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>

<h4><strong>Spark</strong></h4>
<div class="code"><pre class="code literal-block"><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;SPARK_HOME&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;/home/spark-2.3.2-bin-hadoop2.7&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;JAVA_HOME&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;/home/jdk1.8.0_181&quot;</span>
<span class="n">spark_home</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;SPARK_HOME&quot;</span><span class="p">)</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">spark_home</span> <span class="o">+</span> <span class="s2">&quot;/python&quot;</span><span class="p">)</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">spark_home</span><span class="p">,</span> <span class="s2">&quot;python/lib/py4j-0.10.7-src.zip&quot;</span><span class="p">))</span>

<span class="kn">from</span>  <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkContext</span>
<span class="kn">from</span> <span class="nn">pyspark.conf</span> <span class="kn">import</span> <span class="n">SparkConf</span>
<span class="n">CLUSTER_URL</span> <span class="o">=</span> <span class="s2">&quot;spark://address:7077&quot;</span>
<span class="n">conf</span> <span class="o">=</span> <span class="n">SparkConf</span><span class="p">()</span>
<span class="n">conf</span><span class="o">.</span><span class="n">setMaster</span><span class="p">(</span><span class="n">CLUSTER_URL</span><span class="p">)</span><span class="o">.</span><span class="n">setAppName</span><span class="p">(</span><span class="s2">&quot;CTR Analysis&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;spark.executor.memory&quot;</span><span class="p">,</span> <span class="s2">&quot;120g&quot;</span><span class="p">)</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="p">(</span><span class="n">conf</span><span class="o">=</span><span class="n">conf</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sc</span><span class="o">.</span><span class="n">version</span><span class="p">)</span>
</pre></div>

<h2><strong>Reading CSV File</strong></h2>
<h4><strong>Pandas</strong></h4>
<div class="code"><pre class="code literal-block">df = pd.read_csv(data_file_path, names=cols, error_bad_lines=False, warn_bad_lines=True, sep=&#39;,&#39;)
</pre></div>

<h4><strong>Spark</strong></h4>
<div class="code"><pre class="code literal-block"><span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StructType</span><span class="p">,</span> <span class="n">StructField</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">DoubleType</span><span class="p">,</span> <span class="n">IntegerType</span><span class="p">,</span> <span class="n">StringType</span>
<span class="n">file_location</span> <span class="o">=</span> <span class="s2">&quot;hdfs://address:port/hadoop/dataNode/pyspark/data.csv&quot;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">file_location</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>
<span class="c1"># df = spark.read.csv(file_location, header=False, inferSchema=True, sep=&quot;,&quot;)</span>
<span class="c1"># df.cache()</span>
</pre></div>

<h2><strong>Cleaning data</strong></h2>
<h4><strong>Pandas</strong></h4>
<div class="code"><pre class="code literal-block"><span class="n">numeric_cols</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">[</span><span class="n">&#39;label&#39;,&#39;win_price&#39;,&#39;ctr&#39;,&#39;bid_cpc&#39;</span><span class="o">]</span>
<span class="n">df</span><span class="o">[</span><span class="n">numeric_cols</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="o">[</span><span class="n">numeric_cols</span><span class="o">]</span><span class="p">.</span><span class="n">convert_objects</span><span class="p">(</span><span class="n">convert_numeric</span><span class="o">=</span><span class="k">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="k">True</span><span class="p">,</span><span class="w"> </span><span class="n">subset</span><span class="o">=</span><span class="n">numeric_cols</span><span class="p">)</span>
</pre></div>

<h4><strong>Spark</strong></h4>
<div class="code"><pre class="code literal-block">numeric_cols = [&#39;label&#39;,&#39;win_price&#39;,&#39;ctr&#39;,&#39;bid_cpc&#39;]
df = df.dropna(subset=numeric_cols)
</pre></div>

<h2><strong>Calculating Spend, CTR, CPC Per Algo</strong></h2>
<h4><strong>Pandas</strong></h4>
<div class="code"><pre class="code literal-block">data = df.groupby([&#39;algo&#39;]).agg({&#39;win_price&#39;: np.sum, c_label:{&#39;clicks&#39;:np.sum, &#39;wins&#39;:&#39;count&#39;}}).reset_index()
data[(&#39;win_price&#39;,&#39;sum&#39;)] = data[(&#39;win_price&#39;,&#39;sum&#39;)] / 1000.
data[&#39;ecpc&#39;] = data[(&#39;win_price&#39;,&#39;sum&#39;)] / data[(&#39;label,&#39;clicks&#39;)]
data = pd.DataFrame(data.to_records())
data.columns = [&#39;&#39;,algo, &#39;spend&#39;, &#39;number of impressions&#39;, &#39;number of clicks&#39;, &#39;effective cpc&#39;]
</pre></div>

<h4><strong>Spark</strong></h4>
<div class="code"><pre class="code literal-block"><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">udf</span>
<span class="kn">import</span> <span class="nn">pyspark.sql.functions</span> <span class="k">as</span> <span class="nn">f</span>

<span class="k">def</span> <span class="nf">divide_by_1000</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">/</span><span class="mf">1000.0</span>

<span class="n">udfdivide_by_1000</span> <span class="o">=</span> <span class="n">udf</span><span class="p">(</span><span class="n">divide_by_1000</span><span class="p">,</span> <span class="n">DoubleType</span><span class="p">())</span>

<span class="n">data_wins</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;algo&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span> <span class="p">{</span><span class="s1">&#39;win_price&#39;</span><span class="p">:</span> <span class="s1">&#39;sum&#39;</span><span class="p">,</span> <span class="s1">&#39;label: &#39;</span><span class="n">count</span><span class="s1">&#39;})</span>
<span class="n">data_clicks</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;algo&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s1">&#39;label: &#39;</span><span class="nb">sum</span><span class="s1">&#39;})</span>
<span class="c1"># print data_wins.columns</span>
<span class="c1"># print data_clicks.columns</span>
<span class="c1"># Rename the columns</span>
<span class="n">data_wins</span> <span class="o">=</span> <span class="n">data_wins</span><span class="o">.</span><span class="n">withColumnRenamed</span><span class="p">(</span><span class="s2">&quot;sum(win_price)&quot;</span><span class="p">,</span> <span class="s2">&quot;win_price&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">withColumnRenamed</span><span class="p">(</span><span class="s2">&quot;count(label)&quot;</span><span class="p">,</span> <span class="s2">&quot;wins&quot;</span><span class="p">)</span>
<span class="c1">#     print data_wins.schema</span>
<span class="c1">#     data_wins[&#39;win_price&#39;] = data_wins.win_price/1000.</span>
<span class="n">data_wins</span> <span class="o">=</span> <span class="p">(</span><span class="n">data_wins</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;win_price&quot;</span><span class="p">,</span><span class="n">udfdivide_by_1000</span><span class="p">(</span><span class="s2">&quot;win_price&quot;</span><span class="p">)))</span>
<span class="n">data_clicks</span> <span class="o">=</span> <span class="n">data_clicks</span><span class="o">.</span><span class="n">withColumnRenamed</span><span class="p">(</span><span class="s2">&quot;sum(label)&quot;</span><span class="p">,</span> <span class="s2">&quot;clicks&quot;</span><span class="p">)</span>
<span class="c1">#     print data_wins.columns</span>
<span class="c1"># print data_clicks.columns</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data_wins</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_clicks</span><span class="p">,</span> <span class="n">on</span> <span class="o">=</span> <span class="s1">&#39;algo&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;inner&#39;</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;effective cpc&quot;</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;win_price&quot;</span><span class="p">)</span><span class="o">/</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

<div id="disqus_thread"></div>
<script>
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>