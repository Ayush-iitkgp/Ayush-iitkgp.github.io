<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ayush Pandey (Posts about Application of Novelty Detection Algorithms to predict Electricity Theft)</title><link>http://Ayush-iitkgp.github.io/</link><description></description><atom:link href="http://Ayush-iitkgp.github.io/categories/application-of-novelty-detection-algorithms-to-predict-electricity-theft.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Tue, 18 Jan 2022 21:34:42 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>One-Class Classification Algorithms</title><link>http://Ayush-iitkgp.github.io/posts/one-class-classification-algorithms/</link><dc:creator>Ayush Pandey</dc:creator><description>&lt;p&gt;In my &lt;a href="http://Ayush-iitkgp.github.io/posts/when-does-traditional-classification-algorithm-fail/"&gt;previous blog entry&lt;/a&gt;, I have put forth a case for when the traditional classification algorithms do not perform well i.e. when the training data has reasonable level of imbalance between the various classes. The &lt;a href="https://drive.google.com/file/d/0B2oOdWdSJWa1NF8ySXhvR1ZvODA/view?usp=sharing"&gt;problem statement&lt;/a&gt; that I was trying to solve had a similar problem of the skewed distribution of the training data. &lt;strong&gt;The power company had only created the database of fraudulent customers&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;As I mentioned in my previous blog post, there are 2 methods to tackle the case when we have data from only one class:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The first method is an obvious approach to generate an artificial second class and proceed with traditional classification algorithms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second one is to modify the existing classification algoriths to learn on the data from only one class. These algorithms are called "one-class classfication algorithms" and include one-class SVM, One-Class K-Means, One-Class K-Nearest Neighbor, and One-Class Gaussian.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this blog entry, I will elaborate on the second method and explain the mathematics behind the one-class classification algorithms and how it improves over the traditional classification algorithms. &lt;/p&gt;
&lt;h3&gt;Fundamental difference between Binary and One Class Classification Algorithms&lt;/h3&gt;
&lt;p&gt;Binary classification algorithms are &lt;em&gt;discriminatory in nature&lt;/em&gt;, since they learn to discriminate between classes using all data classes to create a hyperplane(as seen in the fig. below) and use the hyperplane to label a new sample. In case of imbalance between the classes, the discriminatory methods can not be used to their full potential, since by their very nature, they rely on data from all classes to build the hyperplane that separate the various classes.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/binaryClassification.png" alt="Binary Classification Hyperplane" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;Binary Classification Hyperplane&lt;/center&gt;&lt;br&gt;
&lt;p&gt;Where as the one-class algorithms are based on &lt;em&gt;recognition&lt;/em&gt; since their aim is to recognize data from a particular class, and reject data from all other classes. This is accomplished by creating a boundary that encompasses all the data belonging to the target class within itself, so when a new sample arrives the algorithm only has to check whether it lies within the boundary or outside and accordingly classify the sample as belonging to the target class or the outlier.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/oneClassClassification.png" alt="One-Class Classification Boundary" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;One-Class Classification Boundary&lt;/center&gt;&lt;br&gt;
&lt;h3&gt;Mathematics behind different One-Class Classification Algorithms&lt;/h3&gt;
&lt;p&gt;In this section, I will explain the mathematics behind different one-class machine learning algorithms by taking a cue from &lt;a href="http://file.scirp.org/pdf/JBiSE20100300003_45072138.pdf"&gt;this research paper&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Gaussian&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;This is basically a density estimation model. It assumes that the training data are the samples from the &lt;em&gt;Multivariate Normal Population&lt;/em&gt;, therefore for a test sample (say z) having n-feaures, the probability of it belonging to the target class can be calculated as follows:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/one-classGaussian.png" alt="one-class gaussian" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the parameters μ and Σ are the &lt;em&gt;poputation mean and covariance&lt;/em&gt;. Hence, the objective function of this machine learning algorithm is to determine the estimates for μ and Σ. Using the &lt;strong&gt;method of maximum likelihood estimator&lt;/strong&gt;, we can show that the sample mean and sample covariance are the unbiased and consistent estimators for population mean and variance respectively. Hence, once we calculate the probability p(z), we can set a threshold to determine whether a new sample is outlier or not.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Kmeans&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;In this method, we first classify the training data into k clusters (which is chosen as per our requirements). Then, for a new sample (say z), the distance &lt;em&gt;d(z)&lt;/em&gt; is calculated as the minimum distance of the sample from the centroid of all the k clusters. Now if &lt;em&gt;d(z)&lt;/em&gt; is less than a particular thereshold (which is again chosen as per our requirements), then the sample belongs to the target class otherwise it is classified as the outlier.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class K-Nearest Neighbor&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Let us take note of some notation before we understand the mathematics behind the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;d(z,y)&lt;/em&gt; : distance between two samples z and y&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;As I mentioned in my previous blog post, there are 2 methods to tackle the case when we have data from only one class:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The first method is an obvious approach to generate an artificial second class and proceed with traditional classification algorithms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second one is to modify the existing classification algoriths to learn on the data from only one class. These algorithms are called "one-class classfication algorithms" and include one-class SVM, One-Class K-Means, One-Class K-Nearest Neighbor, and One-Class Gaussian.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this blog entry, I will elaborate on the second method and explain the mathematics behind the one-class classification algorithms and how it improves over the traditional classification algorithms. &lt;/p&gt;
&lt;h3&gt;Fundamental difference between Binary and One Class Classification Algorithms&lt;/h3&gt;
&lt;p&gt;Binary classification algorithms are &lt;em&gt;discriminatory in nature&lt;/em&gt;, since they learn to discriminate between classes using all data classes to create a hyperplane(as seen in the fig. below) and use the hyperplane to label a new sample. In case of imbalance between the classes, the discriminatory methods can not be used to their full potential, since by their very nature, they rely on data from all classes to build the hyperplane that separate the various classes.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/binaryClassification.png" alt="Binary Classification Hyperplane" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;Binary Classification Hyperplane&lt;/center&gt;&lt;br&gt;
&lt;p&gt;Where as the one-class algorithms are based on &lt;em&gt;recognition&lt;/em&gt; since their aim is to recognize data from a particular class, and reject data from all other classes. This is accomplished by creating a boundary that encompasses all the data belonging to the target class within itself, so when a new sample arrives the algorithm only has to check whether it lies within the boundary or outside and accordingly classify the sample as belonging to the target class or the outlier.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/oneClassClassification.png" alt="One-Class Classification Boundary" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;One-Class Classification Boundary&lt;/center&gt;&lt;br&gt;
&lt;h3&gt;Mathematics behind different One-Class Classification Algorithms&lt;/h3&gt;
&lt;p&gt;In this section, I will explain the mathematics behind different one-class machine learning algorithms by taking a cue from &lt;a href="http://file.scirp.org/pdf/JBiSE20100300003_45072138.pdf"&gt;this research paper&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Gaussian&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;This is basically a density estimation model. It assumes that the training data are the samples from the &lt;em&gt;Multivariate Normal Population&lt;/em&gt;, therefore for a test sample (say z) having n-feaures, the probability of it belonging to the target class can be calculated as follows:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/one-classGaussian.png" alt="one-class gaussian" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the parameters μ and Σ are the &lt;em&gt;poputation mean and covariance&lt;/em&gt;. Hence, the objective function of this machine learning algorithm is to determine the estimates for μ and Σ. Using the &lt;strong&gt;method of maximum likelihood estimator&lt;/strong&gt;, we can show that the sample mean and sample covariance are the unbiased and consistent estimators for population mean and variance respectively. Hence, once we calculate the probability p(z), we can set a threshold to determine whether a new sample is outlier or not.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Kmeans&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;In this method, we first classify the training data into k clusters (which is chosen as per our requirements). Then, for a new sample (say z), the distance &lt;em&gt;d(z)&lt;/em&gt; is calculated as the minimum distance of the sample from the centroid of all the k clusters. Now if &lt;em&gt;d(z)&lt;/em&gt; is less than a particular thereshold (which is again chosen as per our requirements), then the sample belongs to the target class otherwise it is classified as the outlier.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class K-Nearest Neighbor&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Let us take note of some notation before we understand the mathematics behind the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;d(z,y)&lt;/em&gt; : distance between two samples z and y&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The first method is an obvious approach to generate an artificial second class and proceed with traditional classification algorithms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second one is to modify the existing classification algoriths to learn on the data from only one class. These algorithms are called "one-class classfication algorithms" and include one-class SVM, One-Class K-Means, One-Class K-Nearest Neighbor, and One-Class Gaussian.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this blog entry, I will elaborate on the second method and explain the mathematics behind the one-class classification algorithms and how it improves over the traditional classification algorithms. &lt;/p&gt;
&lt;h3&gt;Fundamental difference between Binary and One Class Classification Algorithms&lt;/h3&gt;
&lt;p&gt;Binary classification algorithms are &lt;em&gt;discriminatory in nature&lt;/em&gt;, since they learn to discriminate between classes using all data classes to create a hyperplane(as seen in the fig. below) and use the hyperplane to label a new sample. In case of imbalance between the classes, the discriminatory methods can not be used to their full potential, since by their very nature, they rely on data from all classes to build the hyperplane that separate the various classes.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/binaryClassification.png" alt="Binary Classification Hyperplane" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;Binary Classification Hyperplane&lt;/center&gt;&lt;br&gt;
&lt;p&gt;Where as the one-class algorithms are based on &lt;em&gt;recognition&lt;/em&gt; since their aim is to recognize data from a particular class, and reject data from all other classes. This is accomplished by creating a boundary that encompasses all the data belonging to the target class within itself, so when a new sample arrives the algorithm only has to check whether it lies within the boundary or outside and accordingly classify the sample as belonging to the target class or the outlier.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/oneClassClassification.png" alt="One-Class Classification Boundary" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;One-Class Classification Boundary&lt;/center&gt;&lt;br&gt;
&lt;h3&gt;Mathematics behind different One-Class Classification Algorithms&lt;/h3&gt;
&lt;p&gt;In this section, I will explain the mathematics behind different one-class machine learning algorithms by taking a cue from &lt;a href="http://file.scirp.org/pdf/JBiSE20100300003_45072138.pdf"&gt;this research paper&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Gaussian&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;This is basically a density estimation model. It assumes that the training data are the samples from the &lt;em&gt;Multivariate Normal Population&lt;/em&gt;, therefore for a test sample (say z) having n-feaures, the probability of it belonging to the target class can be calculated as follows:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/one-classGaussian.png" alt="one-class gaussian" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the parameters μ and Σ are the &lt;em&gt;poputation mean and covariance&lt;/em&gt;. Hence, the objective function of this machine learning algorithm is to determine the estimates for μ and Σ. Using the &lt;strong&gt;method of maximum likelihood estimator&lt;/strong&gt;, we can show that the sample mean and sample covariance are the unbiased and consistent estimators for population mean and variance respectively. Hence, once we calculate the probability p(z), we can set a threshold to determine whether a new sample is outlier or not.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Kmeans&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;In this method, we first classify the training data into k clusters (which is chosen as per our requirements). Then, for a new sample (say z), the distance &lt;em&gt;d(z)&lt;/em&gt; is calculated as the minimum distance of the sample from the centroid of all the k clusters. Now if &lt;em&gt;d(z)&lt;/em&gt; is less than a particular thereshold (which is again chosen as per our requirements), then the sample belongs to the target class otherwise it is classified as the outlier.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class K-Nearest Neighbor&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Let us take note of some notation before we understand the mathematics behind the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;d(z,y)&lt;/em&gt; : distance between two samples z and y&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;In this blog entry, I will elaborate on the second method and explain the mathematics behind the one-class classification algorithms and how it improves over the traditional classification algorithms. &lt;/p&gt;
&lt;h3&gt;Fundamental difference between Binary and One Class Classification Algorithms&lt;/h3&gt;
&lt;p&gt;Binary classification algorithms are &lt;em&gt;discriminatory in nature&lt;/em&gt;, since they learn to discriminate between classes using all data classes to create a hyperplane(as seen in the fig. below) and use the hyperplane to label a new sample. In case of imbalance between the classes, the discriminatory methods can not be used to their full potential, since by their very nature, they rely on data from all classes to build the hyperplane that separate the various classes.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/binaryClassification.png" alt="Binary Classification Hyperplane" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;Binary Classification Hyperplane&lt;/center&gt;&lt;br&gt;
&lt;p&gt;Where as the one-class algorithms are based on &lt;em&gt;recognition&lt;/em&gt; since their aim is to recognize data from a particular class, and reject data from all other classes. This is accomplished by creating a boundary that encompasses all the data belonging to the target class within itself, so when a new sample arrives the algorithm only has to check whether it lies within the boundary or outside and accordingly classify the sample as belonging to the target class or the outlier.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/oneClassClassification.png" alt="One-Class Classification Boundary" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;One-Class Classification Boundary&lt;/center&gt;&lt;br&gt;
&lt;h3&gt;Mathematics behind different One-Class Classification Algorithms&lt;/h3&gt;
&lt;p&gt;In this section, I will explain the mathematics behind different one-class machine learning algorithms by taking a cue from &lt;a href="http://file.scirp.org/pdf/JBiSE20100300003_45072138.pdf"&gt;this research paper&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Gaussian&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;This is basically a density estimation model. It assumes that the training data are the samples from the &lt;em&gt;Multivariate Normal Population&lt;/em&gt;, therefore for a test sample (say z) having n-feaures, the probability of it belonging to the target class can be calculated as follows:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/one-classGaussian.png" alt="one-class gaussian" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the parameters μ and Σ are the &lt;em&gt;poputation mean and covariance&lt;/em&gt;. Hence, the objective function of this machine learning algorithm is to determine the estimates for μ and Σ. Using the &lt;strong&gt;method of maximum likelihood estimator&lt;/strong&gt;, we can show that the sample mean and sample covariance are the unbiased and consistent estimators for population mean and variance respectively. Hence, once we calculate the probability p(z), we can set a threshold to determine whether a new sample is outlier or not.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Kmeans&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;In this method, we first classify the training data into k clusters (which is chosen as per our requirements). Then, for a new sample (say z), the distance &lt;em&gt;d(z)&lt;/em&gt; is calculated as the minimum distance of the sample from the centroid of all the k clusters. Now if &lt;em&gt;d(z)&lt;/em&gt; is less than a particular thereshold (which is again chosen as per our requirements), then the sample belongs to the target class otherwise it is classified as the outlier.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class K-Nearest Neighbor&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Let us take note of some notation before we understand the mathematics behind the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;d(z,y)&lt;/em&gt; : distance between two samples z and y&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;h3&gt;Fundamental difference between Binary and One Class Classification Algorithms&lt;/h3&gt;
&lt;p&gt;Binary classification algorithms are &lt;em&gt;discriminatory in nature&lt;/em&gt;, since they learn to discriminate between classes using all data classes to create a hyperplane(as seen in the fig. below) and use the hyperplane to label a new sample. In case of imbalance between the classes, the discriminatory methods can not be used to their full potential, since by their very nature, they rely on data from all classes to build the hyperplane that separate the various classes.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/binaryClassification.png" alt="Binary Classification Hyperplane" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;Binary Classification Hyperplane&lt;/center&gt;&lt;br&gt;
&lt;p&gt;Where as the one-class algorithms are based on &lt;em&gt;recognition&lt;/em&gt; since their aim is to recognize data from a particular class, and reject data from all other classes. This is accomplished by creating a boundary that encompasses all the data belonging to the target class within itself, so when a new sample arrives the algorithm only has to check whether it lies within the boundary or outside and accordingly classify the sample as belonging to the target class or the outlier.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/oneClassClassification.png" alt="One-Class Classification Boundary" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;One-Class Classification Boundary&lt;/center&gt;&lt;br&gt;
&lt;h3&gt;Mathematics behind different One-Class Classification Algorithms&lt;/h3&gt;
&lt;p&gt;In this section, I will explain the mathematics behind different one-class machine learning algorithms by taking a cue from &lt;a href="http://file.scirp.org/pdf/JBiSE20100300003_45072138.pdf"&gt;this research paper&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Gaussian&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;This is basically a density estimation model. It assumes that the training data are the samples from the &lt;em&gt;Multivariate Normal Population&lt;/em&gt;, therefore for a test sample (say z) having n-feaures, the probability of it belonging to the target class can be calculated as follows:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/one-classGaussian.png" alt="one-class gaussian" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the parameters μ and Σ are the &lt;em&gt;poputation mean and covariance&lt;/em&gt;. Hence, the objective function of this machine learning algorithm is to determine the estimates for μ and Σ. Using the &lt;strong&gt;method of maximum likelihood estimator&lt;/strong&gt;, we can show that the sample mean and sample covariance are the unbiased and consistent estimators for population mean and variance respectively. Hence, once we calculate the probability p(z), we can set a threshold to determine whether a new sample is outlier or not.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Kmeans&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;In this method, we first classify the training data into k clusters (which is chosen as per our requirements). Then, for a new sample (say z), the distance &lt;em&gt;d(z)&lt;/em&gt; is calculated as the minimum distance of the sample from the centroid of all the k clusters. Now if &lt;em&gt;d(z)&lt;/em&gt; is less than a particular thereshold (which is again chosen as per our requirements), then the sample belongs to the target class otherwise it is classified as the outlier.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class K-Nearest Neighbor&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Let us take note of some notation before we understand the mathematics behind the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;d(z,y)&lt;/em&gt; : distance between two samples z and y&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;Binary classification algorithms are &lt;em&gt;discriminatory in nature&lt;/em&gt;, since they learn to discriminate between classes using all data classes to create a hyperplane(as seen in the fig. below) and use the hyperplane to label a new sample. In case of imbalance between the classes, the discriminatory methods can not be used to their full potential, since by their very nature, they rely on data from all classes to build the hyperplane that separate the various classes.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/binaryClassification.png" alt="Binary Classification Hyperplane" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;Binary Classification Hyperplane&lt;/center&gt;&lt;br&gt;
&lt;p&gt;Where as the one-class algorithms are based on &lt;em&gt;recognition&lt;/em&gt; since their aim is to recognize data from a particular class, and reject data from all other classes. This is accomplished by creating a boundary that encompasses all the data belonging to the target class within itself, so when a new sample arrives the algorithm only has to check whether it lies within the boundary or outside and accordingly classify the sample as belonging to the target class or the outlier.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/oneClassClassification.png" alt="One-Class Classification Boundary" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;One-Class Classification Boundary&lt;/center&gt;&lt;br&gt;
&lt;h3&gt;Mathematics behind different One-Class Classification Algorithms&lt;/h3&gt;
&lt;p&gt;In this section, I will explain the mathematics behind different one-class machine learning algorithms by taking a cue from &lt;a href="http://file.scirp.org/pdf/JBiSE20100300003_45072138.pdf"&gt;this research paper&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Gaussian&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;This is basically a density estimation model. It assumes that the training data are the samples from the &lt;em&gt;Multivariate Normal Population&lt;/em&gt;, therefore for a test sample (say z) having n-feaures, the probability of it belonging to the target class can be calculated as follows:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/one-classGaussian.png" alt="one-class gaussian" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the parameters μ and Σ are the &lt;em&gt;poputation mean and covariance&lt;/em&gt;. Hence, the objective function of this machine learning algorithm is to determine the estimates for μ and Σ. Using the &lt;strong&gt;method of maximum likelihood estimator&lt;/strong&gt;, we can show that the sample mean and sample covariance are the unbiased and consistent estimators for population mean and variance respectively. Hence, once we calculate the probability p(z), we can set a threshold to determine whether a new sample is outlier or not.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Kmeans&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;In this method, we first classify the training data into k clusters (which is chosen as per our requirements). Then, for a new sample (say z), the distance &lt;em&gt;d(z)&lt;/em&gt; is calculated as the minimum distance of the sample from the centroid of all the k clusters. Now if &lt;em&gt;d(z)&lt;/em&gt; is less than a particular thereshold (which is again chosen as per our requirements), then the sample belongs to the target class otherwise it is classified as the outlier.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class K-Nearest Neighbor&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Let us take note of some notation before we understand the mathematics behind the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;d(z,y)&lt;/em&gt; : distance between two samples z and y&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/binaryClassification.png" alt="Binary Classification Hyperplane" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;Binary Classification Hyperplane&lt;/center&gt;&lt;br&gt;
&lt;p&gt;Where as the one-class algorithms are based on &lt;em&gt;recognition&lt;/em&gt; since their aim is to recognize data from a particular class, and reject data from all other classes. This is accomplished by creating a boundary that encompasses all the data belonging to the target class within itself, so when a new sample arrives the algorithm only has to check whether it lies within the boundary or outside and accordingly classify the sample as belonging to the target class or the outlier.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/oneClassClassification.png" alt="One-Class Classification Boundary" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;One-Class Classification Boundary&lt;/center&gt;&lt;br&gt;
&lt;h3&gt;Mathematics behind different One-Class Classification Algorithms&lt;/h3&gt;
&lt;p&gt;In this section, I will explain the mathematics behind different one-class machine learning algorithms by taking a cue from &lt;a href="http://file.scirp.org/pdf/JBiSE20100300003_45072138.pdf"&gt;this research paper&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Gaussian&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;This is basically a density estimation model. It assumes that the training data are the samples from the &lt;em&gt;Multivariate Normal Population&lt;/em&gt;, therefore for a test sample (say z) having n-feaures, the probability of it belonging to the target class can be calculated as follows:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/one-classGaussian.png" alt="one-class gaussian" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the parameters μ and Σ are the &lt;em&gt;poputation mean and covariance&lt;/em&gt;. Hence, the objective function of this machine learning algorithm is to determine the estimates for μ and Σ. Using the &lt;strong&gt;method of maximum likelihood estimator&lt;/strong&gt;, we can show that the sample mean and sample covariance are the unbiased and consistent estimators for population mean and variance respectively. Hence, once we calculate the probability p(z), we can set a threshold to determine whether a new sample is outlier or not.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Kmeans&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;In this method, we first classify the training data into k clusters (which is chosen as per our requirements). Then, for a new sample (say z), the distance &lt;em&gt;d(z)&lt;/em&gt; is calculated as the minimum distance of the sample from the centroid of all the k clusters. Now if &lt;em&gt;d(z)&lt;/em&gt; is less than a particular thereshold (which is again chosen as per our requirements), then the sample belongs to the target class otherwise it is classified as the outlier.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class K-Nearest Neighbor&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Let us take note of some notation before we understand the mathematics behind the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;d(z,y)&lt;/em&gt; : distance between two samples z and y&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;
&lt;br&gt;
&lt;p&gt;Where as the one-class algorithms are based on &lt;em&gt;recognition&lt;/em&gt; since their aim is to recognize data from a particular class, and reject data from all other classes. This is accomplished by creating a boundary that encompasses all the data belonging to the target class within itself, so when a new sample arrives the algorithm only has to check whether it lies within the boundary or outside and accordingly classify the sample as belonging to the target class or the outlier.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/oneClassClassification.png" alt="One-Class Classification Boundary" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;One-Class Classification Boundary&lt;/center&gt;&lt;br&gt;
&lt;h3&gt;Mathematics behind different One-Class Classification Algorithms&lt;/h3&gt;
&lt;p&gt;In this section, I will explain the mathematics behind different one-class machine learning algorithms by taking a cue from &lt;a href="http://file.scirp.org/pdf/JBiSE20100300003_45072138.pdf"&gt;this research paper&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Gaussian&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;This is basically a density estimation model. It assumes that the training data are the samples from the &lt;em&gt;Multivariate Normal Population&lt;/em&gt;, therefore for a test sample (say z) having n-feaures, the probability of it belonging to the target class can be calculated as follows:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/one-classGaussian.png" alt="one-class gaussian" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the parameters μ and Σ are the &lt;em&gt;poputation mean and covariance&lt;/em&gt;. Hence, the objective function of this machine learning algorithm is to determine the estimates for μ and Σ. Using the &lt;strong&gt;method of maximum likelihood estimator&lt;/strong&gt;, we can show that the sample mean and sample covariance are the unbiased and consistent estimators for population mean and variance respectively. Hence, once we calculate the probability p(z), we can set a threshold to determine whether a new sample is outlier or not.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Kmeans&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;In this method, we first classify the training data into k clusters (which is chosen as per our requirements). Then, for a new sample (say z), the distance &lt;em&gt;d(z)&lt;/em&gt; is calculated as the minimum distance of the sample from the centroid of all the k clusters. Now if &lt;em&gt;d(z)&lt;/em&gt; is less than a particular thereshold (which is again chosen as per our requirements), then the sample belongs to the target class otherwise it is classified as the outlier.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class K-Nearest Neighbor&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Let us take note of some notation before we understand the mathematics behind the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;d(z,y)&lt;/em&gt; : distance between two samples z and y&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/oneClassClassification.png" alt="One-Class Classification Boundary" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;One-Class Classification Boundary&lt;/center&gt;&lt;br&gt;
&lt;h3&gt;Mathematics behind different One-Class Classification Algorithms&lt;/h3&gt;
&lt;p&gt;In this section, I will explain the mathematics behind different one-class machine learning algorithms by taking a cue from &lt;a href="http://file.scirp.org/pdf/JBiSE20100300003_45072138.pdf"&gt;this research paper&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Gaussian&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;This is basically a density estimation model. It assumes that the training data are the samples from the &lt;em&gt;Multivariate Normal Population&lt;/em&gt;, therefore for a test sample (say z) having n-feaures, the probability of it belonging to the target class can be calculated as follows:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/one-classGaussian.png" alt="one-class gaussian" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the parameters μ and Σ are the &lt;em&gt;poputation mean and covariance&lt;/em&gt;. Hence, the objective function of this machine learning algorithm is to determine the estimates for μ and Σ. Using the &lt;strong&gt;method of maximum likelihood estimator&lt;/strong&gt;, we can show that the sample mean and sample covariance are the unbiased and consistent estimators for population mean and variance respectively. Hence, once we calculate the probability p(z), we can set a threshold to determine whether a new sample is outlier or not.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Kmeans&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;In this method, we first classify the training data into k clusters (which is chosen as per our requirements). Then, for a new sample (say z), the distance &lt;em&gt;d(z)&lt;/em&gt; is calculated as the minimum distance of the sample from the centroid of all the k clusters. Now if &lt;em&gt;d(z)&lt;/em&gt; is less than a particular thereshold (which is again chosen as per our requirements), then the sample belongs to the target class otherwise it is classified as the outlier.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class K-Nearest Neighbor&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Let us take note of some notation before we understand the mathematics behind the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;d(z,y)&lt;/em&gt; : distance between two samples z and y&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;
&lt;br&gt;
&lt;h3&gt;Mathematics behind different One-Class Classification Algorithms&lt;/h3&gt;
&lt;p&gt;In this section, I will explain the mathematics behind different one-class machine learning algorithms by taking a cue from &lt;a href="http://file.scirp.org/pdf/JBiSE20100300003_45072138.pdf"&gt;this research paper&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Gaussian&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;This is basically a density estimation model. It assumes that the training data are the samples from the &lt;em&gt;Multivariate Normal Population&lt;/em&gt;, therefore for a test sample (say z) having n-feaures, the probability of it belonging to the target class can be calculated as follows:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/one-classGaussian.png" alt="one-class gaussian" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the parameters μ and Σ are the &lt;em&gt;poputation mean and covariance&lt;/em&gt;. Hence, the objective function of this machine learning algorithm is to determine the estimates for μ and Σ. Using the &lt;strong&gt;method of maximum likelihood estimator&lt;/strong&gt;, we can show that the sample mean and sample covariance are the unbiased and consistent estimators for population mean and variance respectively. Hence, once we calculate the probability p(z), we can set a threshold to determine whether a new sample is outlier or not.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Kmeans&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;In this method, we first classify the training data into k clusters (which is chosen as per our requirements). Then, for a new sample (say z), the distance &lt;em&gt;d(z)&lt;/em&gt; is calculated as the minimum distance of the sample from the centroid of all the k clusters. Now if &lt;em&gt;d(z)&lt;/em&gt; is less than a particular thereshold (which is again chosen as per our requirements), then the sample belongs to the target class otherwise it is classified as the outlier.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class K-Nearest Neighbor&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Let us take note of some notation before we understand the mathematics behind the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;d(z,y)&lt;/em&gt; : distance between two samples z and y&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;In this section, I will explain the mathematics behind different one-class machine learning algorithms by taking a cue from &lt;a href="http://file.scirp.org/pdf/JBiSE20100300003_45072138.pdf"&gt;this research paper&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Gaussian&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;This is basically a density estimation model. It assumes that the training data are the samples from the &lt;em&gt;Multivariate Normal Population&lt;/em&gt;, therefore for a test sample (say z) having n-feaures, the probability of it belonging to the target class can be calculated as follows:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/one-classGaussian.png" alt="one-class gaussian" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the parameters μ and Σ are the &lt;em&gt;poputation mean and covariance&lt;/em&gt;. Hence, the objective function of this machine learning algorithm is to determine the estimates for μ and Σ. Using the &lt;strong&gt;method of maximum likelihood estimator&lt;/strong&gt;, we can show that the sample mean and sample covariance are the unbiased and consistent estimators for population mean and variance respectively. Hence, once we calculate the probability p(z), we can set a threshold to determine whether a new sample is outlier or not.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Kmeans&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;In this method, we first classify the training data into k clusters (which is chosen as per our requirements). Then, for a new sample (say z), the distance &lt;em&gt;d(z)&lt;/em&gt; is calculated as the minimum distance of the sample from the centroid of all the k clusters. Now if &lt;em&gt;d(z)&lt;/em&gt; is less than a particular thereshold (which is again chosen as per our requirements), then the sample belongs to the target class otherwise it is classified as the outlier.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class K-Nearest Neighbor&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Let us take note of some notation before we understand the mathematics behind the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;d(z,y)&lt;/em&gt; : distance between two samples z and y&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;h4&gt;&lt;strong&gt;One-Class Gaussian&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;This is basically a density estimation model. It assumes that the training data are the samples from the &lt;em&gt;Multivariate Normal Population&lt;/em&gt;, therefore for a test sample (say z) having n-feaures, the probability of it belonging to the target class can be calculated as follows:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/one-classGaussian.png" alt="one-class gaussian" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the parameters μ and Σ are the &lt;em&gt;poputation mean and covariance&lt;/em&gt;. Hence, the objective function of this machine learning algorithm is to determine the estimates for μ and Σ. Using the &lt;strong&gt;method of maximum likelihood estimator&lt;/strong&gt;, we can show that the sample mean and sample covariance are the unbiased and consistent estimators for population mean and variance respectively. Hence, once we calculate the probability p(z), we can set a threshold to determine whether a new sample is outlier or not.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Kmeans&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;In this method, we first classify the training data into k clusters (which is chosen as per our requirements). Then, for a new sample (say z), the distance &lt;em&gt;d(z)&lt;/em&gt; is calculated as the minimum distance of the sample from the centroid of all the k clusters. Now if &lt;em&gt;d(z)&lt;/em&gt; is less than a particular thereshold (which is again chosen as per our requirements), then the sample belongs to the target class otherwise it is classified as the outlier.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class K-Nearest Neighbor&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Let us take note of some notation before we understand the mathematics behind the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;d(z,y)&lt;/em&gt; : distance between two samples z and y&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;This is basically a density estimation model. It assumes that the training data are the samples from the &lt;em&gt;Multivariate Normal Population&lt;/em&gt;, therefore for a test sample (say z) having n-feaures, the probability of it belonging to the target class can be calculated as follows:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/one-classGaussian.png" alt="one-class gaussian" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the parameters μ and Σ are the &lt;em&gt;poputation mean and covariance&lt;/em&gt;. Hence, the objective function of this machine learning algorithm is to determine the estimates for μ and Σ. Using the &lt;strong&gt;method of maximum likelihood estimator&lt;/strong&gt;, we can show that the sample mean and sample covariance are the unbiased and consistent estimators for population mean and variance respectively. Hence, once we calculate the probability p(z), we can set a threshold to determine whether a new sample is outlier or not.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Kmeans&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;In this method, we first classify the training data into k clusters (which is chosen as per our requirements). Then, for a new sample (say z), the distance &lt;em&gt;d(z)&lt;/em&gt; is calculated as the minimum distance of the sample from the centroid of all the k clusters. Now if &lt;em&gt;d(z)&lt;/em&gt; is less than a particular thereshold (which is again chosen as per our requirements), then the sample belongs to the target class otherwise it is classified as the outlier.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class K-Nearest Neighbor&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Let us take note of some notation before we understand the mathematics behind the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;d(z,y)&lt;/em&gt; : distance between two samples z and y&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/one-classGaussian.png" alt="one-class gaussian" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the parameters μ and Σ are the &lt;em&gt;poputation mean and covariance&lt;/em&gt;. Hence, the objective function of this machine learning algorithm is to determine the estimates for μ and Σ. Using the &lt;strong&gt;method of maximum likelihood estimator&lt;/strong&gt;, we can show that the sample mean and sample covariance are the unbiased and consistent estimators for population mean and variance respectively. Hence, once we calculate the probability p(z), we can set a threshold to determine whether a new sample is outlier or not.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Kmeans&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;In this method, we first classify the training data into k clusters (which is chosen as per our requirements). Then, for a new sample (say z), the distance &lt;em&gt;d(z)&lt;/em&gt; is calculated as the minimum distance of the sample from the centroid of all the k clusters. Now if &lt;em&gt;d(z)&lt;/em&gt; is less than a particular thereshold (which is again chosen as per our requirements), then the sample belongs to the target class otherwise it is classified as the outlier.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class K-Nearest Neighbor&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Let us take note of some notation before we understand the mathematics behind the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;d(z,y)&lt;/em&gt; : distance between two samples z and y&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;
&lt;br&gt;
&lt;p&gt;where the parameters μ and Σ are the &lt;em&gt;poputation mean and covariance&lt;/em&gt;. Hence, the objective function of this machine learning algorithm is to determine the estimates for μ and Σ. Using the &lt;strong&gt;method of maximum likelihood estimator&lt;/strong&gt;, we can show that the sample mean and sample covariance are the unbiased and consistent estimators for population mean and variance respectively. Hence, once we calculate the probability p(z), we can set a threshold to determine whether a new sample is outlier or not.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Kmeans&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;In this method, we first classify the training data into k clusters (which is chosen as per our requirements). Then, for a new sample (say z), the distance &lt;em&gt;d(z)&lt;/em&gt; is calculated as the minimum distance of the sample from the centroid of all the k clusters. Now if &lt;em&gt;d(z)&lt;/em&gt; is less than a particular thereshold (which is again chosen as per our requirements), then the sample belongs to the target class otherwise it is classified as the outlier.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class K-Nearest Neighbor&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Let us take note of some notation before we understand the mathematics behind the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;d(z,y)&lt;/em&gt; : distance between two samples z and y&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;h4&gt;&lt;strong&gt;One-Class Kmeans&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;In this method, we first classify the training data into k clusters (which is chosen as per our requirements). Then, for a new sample (say z), the distance &lt;em&gt;d(z)&lt;/em&gt; is calculated as the minimum distance of the sample from the centroid of all the k clusters. Now if &lt;em&gt;d(z)&lt;/em&gt; is less than a particular thereshold (which is again chosen as per our requirements), then the sample belongs to the target class otherwise it is classified as the outlier.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class K-Nearest Neighbor&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Let us take note of some notation before we understand the mathematics behind the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;d(z,y)&lt;/em&gt; : distance between two samples z and y&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;In this method, we first classify the training data into k clusters (which is chosen as per our requirements). Then, for a new sample (say z), the distance &lt;em&gt;d(z)&lt;/em&gt; is calculated as the minimum distance of the sample from the centroid of all the k clusters. Now if &lt;em&gt;d(z)&lt;/em&gt; is less than a particular thereshold (which is again chosen as per our requirements), then the sample belongs to the target class otherwise it is classified as the outlier.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class K-Nearest Neighbor&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Let us take note of some notation before we understand the mathematics behind the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;d(z,y)&lt;/em&gt; : distance between two samples z and y&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;h4&gt;&lt;strong&gt;One-Class K-Nearest Neighbor&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Let us take note of some notation before we understand the mathematics behind the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;d(z,y)&lt;/em&gt; : distance between two samples z and y&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;Let us take note of some notation before we understand the mathematics behind the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;d(z,y)&lt;/em&gt; : distance between two samples z and y&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;&lt;em&gt;d(z,y)&lt;/em&gt; : distance between two samples z and y&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;
&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;
</description><category>Application of Novelty Detection Algorithms to predict Electricity Theft</category><category>Data Science</category><category>Machine Learning</category><guid>http://Ayush-iitkgp.github.io/posts/one-class-classification-algorithms/</guid><pubDate>Sun, 22 Jan 2017 06:43:21 GMT</pubDate></item><item><title>When does traditional classification algorithm fail?</title><link>http://Ayush-iitkgp.github.io/posts/when-does-traditional-classification-algorithm-fail/</link><dc:creator>Ayush Pandey</dc:creator><description>&lt;p&gt;One of the most intriguing Machine Learning problems that I have come across was during my 3rd year in the college where a startup named Quantta Analytics presented us with the problem statement about a power distribution company which had observed a significant loss of revenue over a period of time. The loss in revenue was mainly becuase of possible power theft by malicious consumers. The power company resorted to periodic vigilance of customers by sampling and &lt;strong&gt;creating a database of only the fraudulent customers&lt;/strong&gt; to curb this practice. The company wanted the vigilance process to be more robust and effective. Hence, the objective of the problem statement was to deploy a machine learning algorithm to provide a list of customers who are likely to commit fraud. So the problem was effectively a classification problem (&lt;strong&gt;with a catch!&lt;/strong&gt;) where given the attributes of a customer, we had to predict where it is likely to commit the electricity theft or not.&lt;/p&gt;
&lt;p&gt;In order to appreciate the problem statement, let us first have the review of the well-known famous classification algorithms. Classification problems try to solve the two or multi-class situation. The goal is to distinguish test data between a number of classes, using training data which has samples from all the possible classes and &lt;strong&gt;training data has reasonable level of balance between the various classes&lt;/strong&gt;. Now the question that arise is - &lt;em&gt;At what levels of imbalance does the use of traditional classifiers becomes futile?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://ieeexplore.ieee.org/document/6406735/"&gt;This paper&lt;/a&gt; has made observation by conducting experiments on various datasets from the UCI repository, and monitoring the performance of the traditional classifiers. I am listing down the most important observations stated in the paper:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The performance of the traditional classifiers start to decline when the imbalance between output classes increase and &lt;strong&gt;the decline becomes prominent at the ratio 1:2.8&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;At the ratio 1:10&lt;/strong&gt;, the performance is so poor for traditional classifiers that it can no longer be trusted.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Figure below shows the initial ratio of the classes present in UCI dataset and the ratio at which the performance of the binary classiﬁers starts to deteriorate.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/BinaryPerformanceTable.png" alt="Binary Classification Algorithm Performance Table" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;
&lt;p&gt;Now the questions that arise are - what if we have the training data which has imbalance between the classes or data only from one class? Why do we need to study such case? And are there any situations where such data is available?&lt;/p&gt;
&lt;p&gt;To answer the latter first, yes there are plenty of situations where we have the data from only one class. Consider a case of a nuclear power plant. We have the measurement of the plant conditions such as temperature, reaction rate when the plant is in working condition. Is it possible to get such measurements in case of an accident? No. Now, if we want to predict the possible scenario of the breakdown of the plant. From the above observations it is sure that the traditional classification algorithms will not perform well. Some other cases are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Detection of oil spill&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In computational biology to predict microRNA gene target&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are 2 methods to tackle the case when we have data from only one class:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The first method is an obvious approach to generate an artificial second class and proceed with traditional classification algorithms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second one is to modify the existing classification algoriths to learn on the data from only one class. These algorithms are called "one-class classfication algorithms" and include one-class SVM, One-Class K-Means, One-Class K-Nearest Neighbor, and One-Class Gaussian.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I will be elaborating on the above two methods in my next blog post. Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;In order to appreciate the problem statement, let us first have the review of the well-known famous classification algorithms. Classification problems try to solve the two or multi-class situation. The goal is to distinguish test data between a number of classes, using training data which has samples from all the possible classes and &lt;strong&gt;training data has reasonable level of balance between the various classes&lt;/strong&gt;. Now the question that arise is - &lt;em&gt;At what levels of imbalance does the use of traditional classifiers becomes futile?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://ieeexplore.ieee.org/document/6406735/"&gt;This paper&lt;/a&gt; has made observation by conducting experiments on various datasets from the UCI repository, and monitoring the performance of the traditional classifiers. I am listing down the most important observations stated in the paper:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The performance of the traditional classifiers start to decline when the imbalance between output classes increase and &lt;strong&gt;the decline becomes prominent at the ratio 1:2.8&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;At the ratio 1:10&lt;/strong&gt;, the performance is so poor for traditional classifiers that it can no longer be trusted.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Figure below shows the initial ratio of the classes present in UCI dataset and the ratio at which the performance of the binary classiﬁers starts to deteriorate.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/BinaryPerformanceTable.png" alt="Binary Classification Algorithm Performance Table" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;
&lt;p&gt;Now the questions that arise are - what if we have the training data which has imbalance between the classes or data only from one class? Why do we need to study such case? And are there any situations where such data is available?&lt;/p&gt;
&lt;p&gt;To answer the latter first, yes there are plenty of situations where we have the data from only one class. Consider a case of a nuclear power plant. We have the measurement of the plant conditions such as temperature, reaction rate when the plant is in working condition. Is it possible to get such measurements in case of an accident? No. Now, if we want to predict the possible scenario of the breakdown of the plant. From the above observations it is sure that the traditional classification algorithms will not perform well. Some other cases are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Detection of oil spill&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In computational biology to predict microRNA gene target&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are 2 methods to tackle the case when we have data from only one class:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The first method is an obvious approach to generate an artificial second class and proceed with traditional classification algorithms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second one is to modify the existing classification algoriths to learn on the data from only one class. These algorithms are called "one-class classfication algorithms" and include one-class SVM, One-Class K-Means, One-Class K-Nearest Neighbor, and One-Class Gaussian.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I will be elaborating on the above two methods in my next blog post. Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;&lt;a href="http://ieeexplore.ieee.org/document/6406735/"&gt;This paper&lt;/a&gt; has made observation by conducting experiments on various datasets from the UCI repository, and monitoring the performance of the traditional classifiers. I am listing down the most important observations stated in the paper:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The performance of the traditional classifiers start to decline when the imbalance between output classes increase and &lt;strong&gt;the decline becomes prominent at the ratio 1:2.8&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;At the ratio 1:10&lt;/strong&gt;, the performance is so poor for traditional classifiers that it can no longer be trusted.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Figure below shows the initial ratio of the classes present in UCI dataset and the ratio at which the performance of the binary classiﬁers starts to deteriorate.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/BinaryPerformanceTable.png" alt="Binary Classification Algorithm Performance Table" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;
&lt;p&gt;Now the questions that arise are - what if we have the training data which has imbalance between the classes or data only from one class? Why do we need to study such case? And are there any situations where such data is available?&lt;/p&gt;
&lt;p&gt;To answer the latter first, yes there are plenty of situations where we have the data from only one class. Consider a case of a nuclear power plant. We have the measurement of the plant conditions such as temperature, reaction rate when the plant is in working condition. Is it possible to get such measurements in case of an accident? No. Now, if we want to predict the possible scenario of the breakdown of the plant. From the above observations it is sure that the traditional classification algorithms will not perform well. Some other cases are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Detection of oil spill&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In computational biology to predict microRNA gene target&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are 2 methods to tackle the case when we have data from only one class:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The first method is an obvious approach to generate an artificial second class and proceed with traditional classification algorithms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second one is to modify the existing classification algoriths to learn on the data from only one class. These algorithms are called "one-class classfication algorithms" and include one-class SVM, One-Class K-Means, One-Class K-Nearest Neighbor, and One-Class Gaussian.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I will be elaborating on the above two methods in my next blog post. Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The performance of the traditional classifiers start to decline when the imbalance between output classes increase and &lt;strong&gt;the decline becomes prominent at the ratio 1:2.8&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;At the ratio 1:10&lt;/strong&gt;, the performance is so poor for traditional classifiers that it can no longer be trusted.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Figure below shows the initial ratio of the classes present in UCI dataset and the ratio at which the performance of the binary classiﬁers starts to deteriorate.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/BinaryPerformanceTable.png" alt="Binary Classification Algorithm Performance Table" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;
&lt;p&gt;Now the questions that arise are - what if we have the training data which has imbalance between the classes or data only from one class? Why do we need to study such case? And are there any situations where such data is available?&lt;/p&gt;
&lt;p&gt;To answer the latter first, yes there are plenty of situations where we have the data from only one class. Consider a case of a nuclear power plant. We have the measurement of the plant conditions such as temperature, reaction rate when the plant is in working condition. Is it possible to get such measurements in case of an accident? No. Now, if we want to predict the possible scenario of the breakdown of the plant. From the above observations it is sure that the traditional classification algorithms will not perform well. Some other cases are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Detection of oil spill&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In computational biology to predict microRNA gene target&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are 2 methods to tackle the case when we have data from only one class:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The first method is an obvious approach to generate an artificial second class and proceed with traditional classification algorithms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second one is to modify the existing classification algoriths to learn on the data from only one class. These algorithms are called "one-class classfication algorithms" and include one-class SVM, One-Class K-Means, One-Class K-Nearest Neighbor, and One-Class Gaussian.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I will be elaborating on the above two methods in my next blog post. Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;Figure below shows the initial ratio of the classes present in UCI dataset and the ratio at which the performance of the binary classiﬁers starts to deteriorate.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/BinaryPerformanceTable.png" alt="Binary Classification Algorithm Performance Table" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;
&lt;p&gt;Now the questions that arise are - what if we have the training data which has imbalance between the classes or data only from one class? Why do we need to study such case? And are there any situations where such data is available?&lt;/p&gt;
&lt;p&gt;To answer the latter first, yes there are plenty of situations where we have the data from only one class. Consider a case of a nuclear power plant. We have the measurement of the plant conditions such as temperature, reaction rate when the plant is in working condition. Is it possible to get such measurements in case of an accident? No. Now, if we want to predict the possible scenario of the breakdown of the plant. From the above observations it is sure that the traditional classification algorithms will not perform well. Some other cases are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Detection of oil spill&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In computational biology to predict microRNA gene target&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are 2 methods to tackle the case when we have data from only one class:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The first method is an obvious approach to generate an artificial second class and proceed with traditional classification algorithms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second one is to modify the existing classification algoriths to learn on the data from only one class. These algorithms are called "one-class classfication algorithms" and include one-class SVM, One-Class K-Means, One-Class K-Nearest Neighbor, and One-Class Gaussian.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I will be elaborating on the above two methods in my next blog post. Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/BinaryPerformanceTable.png" alt="Binary Classification Algorithm Performance Table" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;
&lt;p&gt;Now the questions that arise are - what if we have the training data which has imbalance between the classes or data only from one class? Why do we need to study such case? And are there any situations where such data is available?&lt;/p&gt;
&lt;p&gt;To answer the latter first, yes there are plenty of situations where we have the data from only one class. Consider a case of a nuclear power plant. We have the measurement of the plant conditions such as temperature, reaction rate when the plant is in working condition. Is it possible to get such measurements in case of an accident? No. Now, if we want to predict the possible scenario of the breakdown of the plant. From the above observations it is sure that the traditional classification algorithms will not perform well. Some other cases are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Detection of oil spill&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In computational biology to predict microRNA gene target&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are 2 methods to tackle the case when we have data from only one class:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The first method is an obvious approach to generate an artificial second class and proceed with traditional classification algorithms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second one is to modify the existing classification algoriths to learn on the data from only one class. These algorithms are called "one-class classfication algorithms" and include one-class SVM, One-Class K-Means, One-Class K-Nearest Neighbor, and One-Class Gaussian.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I will be elaborating on the above two methods in my next blog post. Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;Now the questions that arise are - what if we have the training data which has imbalance between the classes or data only from one class? Why do we need to study such case? And are there any situations where such data is available?&lt;/p&gt;
&lt;p&gt;To answer the latter first, yes there are plenty of situations where we have the data from only one class. Consider a case of a nuclear power plant. We have the measurement of the plant conditions such as temperature, reaction rate when the plant is in working condition. Is it possible to get such measurements in case of an accident? No. Now, if we want to predict the possible scenario of the breakdown of the plant. From the above observations it is sure that the traditional classification algorithms will not perform well. Some other cases are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Detection of oil spill&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In computational biology to predict microRNA gene target&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are 2 methods to tackle the case when we have data from only one class:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The first method is an obvious approach to generate an artificial second class and proceed with traditional classification algorithms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second one is to modify the existing classification algoriths to learn on the data from only one class. These algorithms are called "one-class classfication algorithms" and include one-class SVM, One-Class K-Means, One-Class K-Nearest Neighbor, and One-Class Gaussian.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I will be elaborating on the above two methods in my next blog post. Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;To answer the latter first, yes there are plenty of situations where we have the data from only one class. Consider a case of a nuclear power plant. We have the measurement of the plant conditions such as temperature, reaction rate when the plant is in working condition. Is it possible to get such measurements in case of an accident? No. Now, if we want to predict the possible scenario of the breakdown of the plant. From the above observations it is sure that the traditional classification algorithms will not perform well. Some other cases are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Detection of oil spill&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In computational biology to predict microRNA gene target&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are 2 methods to tackle the case when we have data from only one class:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The first method is an obvious approach to generate an artificial second class and proceed with traditional classification algorithms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second one is to modify the existing classification algoriths to learn on the data from only one class. These algorithms are called "one-class classfication algorithms" and include one-class SVM, One-Class K-Means, One-Class K-Nearest Neighbor, and One-Class Gaussian.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I will be elaborating on the above two methods in my next blog post. Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Detection of oil spill&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In computational biology to predict microRNA gene target&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are 2 methods to tackle the case when we have data from only one class:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The first method is an obvious approach to generate an artificial second class and proceed with traditional classification algorithms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second one is to modify the existing classification algoriths to learn on the data from only one class. These algorithms are called "one-class classfication algorithms" and include one-class SVM, One-Class K-Means, One-Class K-Nearest Neighbor, and One-Class Gaussian.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I will be elaborating on the above two methods in my next blog post. Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;There are 2 methods to tackle the case when we have data from only one class:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The first method is an obvious approach to generate an artificial second class and proceed with traditional classification algorithms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second one is to modify the existing classification algoriths to learn on the data from only one class. These algorithms are called "one-class classfication algorithms" and include one-class SVM, One-Class K-Means, One-Class K-Nearest Neighbor, and One-Class Gaussian.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I will be elaborating on the above two methods in my next blog post. Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The first method is an obvious approach to generate an artificial second class and proceed with traditional classification algorithms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second one is to modify the existing classification algoriths to learn on the data from only one class. These algorithms are called "one-class classfication algorithms" and include one-class SVM, One-Class K-Means, One-Class K-Nearest Neighbor, and One-Class Gaussian.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I will be elaborating on the above two methods in my next blog post. Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;p&gt;I will be elaborating on the above two methods in my next blog post. Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;div id="disqus_thread"&gt;&lt;/div&gt;
&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;
&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;

&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/body&gt;&lt;/html&gt;
</description><category>Application of Novelty Detection Algorithms to predict Electricity Theft</category><category>Data Science</category><category>Machine Learning</category><guid>http://Ayush-iitkgp.github.io/posts/when-does-traditional-classification-algorithm-fail/</guid><pubDate>Tue, 17 Jan 2017 06:43:21 GMT</pubDate></item></channel></rss>