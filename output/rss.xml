<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ayush Pandey</title><link>http://Ayush-iitkgp.github.io/</link><description>Ayush Pandey</description><atom:link rel="self" type="application/rss+xml" href="http://Ayush-iitkgp.github.io/rss.xml"></atom:link><language>en</language><lastBuildDate>Mon, 04 Sep 2017 20:30:11 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Google Summer of Code 2017</title><link>http://Ayush-iitkgp.github.io/posts/gsoc-2017/</link><dc:creator>Ayush Pandey</dc:creator><description>&lt;div&gt;&lt;h3&gt;&lt;a href="https://summerofcode.withgoogle.com/projects/#5914180975591424"&gt;Proposal&lt;/a&gt;            &lt;a href="https://drive.google.com/open?id=0B2oOdWdSJWa1b3JvRDR1OHZEUTg"&gt;Poster&lt;/a&gt;            &lt;a href="https://github.com/JuliaDiffEq/DiffEqParamEstim.jl/pulls?q=is%3Apr+is%3Aclosed+author%3AAyush-iitkgp"&gt;Github&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Google Summer of Code 2016 under the Julia Language was an experience of a lifetime which motivated me to apply to this year's program as well. While, my last year project with &lt;a href="http://Ayush-iitkgp.github.io/posts/gsoc-2017/"&gt;Convex.jl&lt;/a&gt; was hardcore mathematics, this time I wanted to work in the field of Machine Learning (mainly it's application in the field where there was a potential but not much had been explored). I was well aware of the applications of Machine Learning techniques in Computer Vision, Natural Language Processing, Stock Market Predictions but I never heard or read anyone saying that they used Machine Learning in Differential Equations. So, as soon as I read about the project &lt;a href="https://julialang.org/soc/projects/diffeq.html#machine-learning-tools-for-classification-of-qualitative-traits-of-differential-equation-solutions"&gt;Machine learning tools for classification of qualitative traits of differential equation solutions&lt;/a&gt;, I knew what I had to do in the coming summers. It's been awesome 4 months working on my project and I am so thankful to Google Summer of Code 2017 program and The Julia Language for providing me such an incredible opportunity. The thanksgiving note would be incomplete without the mention of my mentor &lt;a href="http://www.chrisrackauckas.com/"&gt;Chris Rackauckas&lt;/a&gt; who always helped me whenever I felt like giving up.&lt;/p&gt;
&lt;p&gt;In the remaining blog, I will touch upon the technical aspects of my project and my work:&lt;/p&gt;
&lt;h2&gt;Project Abstract&lt;/h2&gt;
&lt;p&gt;Differential equation models are widely used in many scientific fields that include engineering, physics and biomedical sciences. The so-called “forward problem” that is the problem of solving differential equations for given parameter values in the differential equation models has been extensively studied by mathematicians, physicists, and engineers. However, the “inverse problem”, the problem of parameter estimation based on the measurements of output variables, has not been well explored using modern optimization and statistical methods. Parameter estimation aims to find the unknown parameters of the model which give the best fit to a set of experimental data. In this way, parameters which cannot be measured directly will be determined in order to ensure the best fit of the model with the experimental results. This will be done by globally minimizing an objective function which measures the quality of the fit. This inverse problem usually considers a cost function to be optimized (such as maximum likelihood). This problem has applications in systems biology, HIV-AIDS study.&lt;/p&gt;
&lt;p&gt;The expected outcome of my project was &lt;strong&gt;set of a tools for easily classifying parameters using machine learning tooling for users inexperienced with machine learning.&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;Application - HIV-AIDS Viral Dynamics Study&lt;/h2&gt;
&lt;p&gt;Studies of HIV dynamics in AIDS research are very important for understanding the pathogenesis of HIV infection and for assessing the potency of antiviral therapies. Ordinary differential equation (ODE) models are proposed to describe the interactions between HIV virus and immune cellular response.&lt;/p&gt;
&lt;p&gt;One popular HIV dynamic model can be written as:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/HIV.png" alt="HIV-AIDS Dynamics Differential Equation" height="300px" width="500px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;
&lt;p&gt;where (T) is target cells which are assumed to be produced at a constant rate s and which are assumed to die at rate d per cell. Productive infection by virus (V), occurs by virus interacting with target cells at a rate proportional to the product of their densities i.e at rate βVT, where β is called the infection rate constant. Productively infected cells (I) are assumed to die at rate δ per cell. Virus is produced from productively infected cells at rate p per cell and is assumed to either infect new cells or be cleared. In the basic model, loss of virus by cell infection is included in the clearance process and virus is assumed to be cleared by all mechanisms at rate c per virion.&lt;/p&gt;
&lt;p&gt;Here we assume that the parameters p and c are known and can be obtained from the literature.&lt;/p&gt;
&lt;p&gt;Very similar to any Machine Lerning problem, we approached the problem of parameter estimation of differential equations by 2 ways: the Bayesian approach (where the idea is to find the probability distribution of the parameters) and the optimization approach (where we are interested to know the point estimates of the parameters).&lt;/p&gt;
&lt;h2&gt;Optimization Approach&lt;/h2&gt;
&lt;p&gt;My mentor Chris had integrated the LossFunctions.jl which builds L2Loss objective function to estimate the parameters of the differential equations. I started by implementing the Two-stage method which is based on based on the local smoothing approach and a pseudo-least squares (PsLS) principle under a framework of measurement error in regression models.&lt;/p&gt;
&lt;p&gt;The following is the comparative study of the above two methods:&lt;/p&gt;
&lt;h3&gt;Advantages&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Computational efficiency&lt;/li&gt;
&lt;li&gt;The initial values of the state variables of the differential equations are not required&lt;/li&gt;
&lt;li&gt;Providing good initial estimates of the unknown parameters for other computationally-intensive methods to further refine the estimates rapidly&lt;/li&gt;
&lt;li&gt;Easing of the convergence problem&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Disadvantages&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;This method does not converge to the global/local minima as the Non-Linear regression does if the cost function is convex/concave.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I also wrote implementations and test cases for supporting different optimizers and algorithms such as:
1. Genetic Algorithm from Evolutionary.jl
2. Stochastic Algorithms from BlackBoxOptim.jl
3. Simulated Annealing, Brent method, Golden Section Search, BFGS algorithm from Optim.jl
4. MathProgBase associated solvers such as IPOPT, NLopt, MOSEK, etc.&lt;/p&gt;
&lt;p&gt;Then, I integrated the PenaltyFunctions.jl with DiffEqParamEstim to add regularization to the loss function such as Tikhonov and Lasso regularization to surmount ill-posedness and ill-conditioning of the parameter estimation problem.&lt;/p&gt;
&lt;h2&gt;Bayesian Approach&lt;/h2&gt;
&lt;p&gt;Our objective was to translate the ODE described in DifferentialEquations.jl using ParameterizedFunctions.jl into the corresponding Stan (a Markov Chain Monte Carlo Bayesian inference engine) code and use Stan.jl to find the probability distribution of the parameters &lt;strong&gt;without writing a single line of Stan code&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The exhaustive list of pull requests can be found &lt;a href="https://github.com/JuliaDiffEq/DiffEqParamEstim.jl/pulls?q=is%3Apr+is%3Aclosed+author%3AAyush-iitkgp"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I am glad to have been successfully implemented what I proposed.&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;[1].&lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2631937/"&gt;Parameter Estimation for Differential Equation Models Using a Framework of Measurement Error in Regression Models&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2].&lt;a href="https://github.com/JuliaDiffEq/DiffEqParamEstim.jl/issues/5"&gt;Parameter estimation: the build_loss_objective #5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3].&lt;a href="http://bmcsystbiol.biomedcentral.com/articles/10.1186/s12918-015-0219-2"&gt;Robust and efficient parameter estimation in dynamic models of biological systems&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[4].&lt;a href="http://faculty.bscb.cornell.edu/~hooker/ODE_Estimation.pdf"&gt;Parameter Estimation for Differential Equations: A Generalized Smoothing Approach&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[5].&lt;a href="http://www.stat.columbia.edu/~gelman/research/published/stan_jebs_2.pdf"&gt;Stan: A probabilistic programming language for Bayesian inference and optimization&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[6]. &lt;a href="https://github.com/JuliaDiffEq/DifferentialEquations.jl/issues/135"&gt;Linking with Stan project #135&lt;/a&gt;&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;

&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;

&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/div&gt;</description><category>GSoC'17</category><guid>http://Ayush-iitkgp.github.io/posts/gsoc-2017/</guid><pubDate>Fri, 25 Aug 2017 20:43:21 GMT</pubDate></item><item><title>One-Class Classification Algorithms</title><link>http://Ayush-iitkgp.github.io/posts/one-class-classification-algorithms/</link><dc:creator>Ayush Pandey</dc:creator><description>&lt;div&gt;&lt;p&gt;In my &lt;a href="http://Ayush-iitkgp.github.io/posts/when-does-traditional-classification-algorithm-fail/"&gt;previous blog entry&lt;/a&gt;, I have put forth a case for when the traditional classification algorithms do not perform well i.e. when the training data has reasonable level of imbalance between the various classes. The &lt;a href="https://drive.google.com/file/d/0B2oOdWdSJWa1NF8ySXhvR1ZvODA/view?usp=sharing"&gt;problem statement&lt;/a&gt; that I was trying to solve had a similar problem of the skewed distribution of the training data. &lt;strong&gt;The power company had only created the database of fraudulent customers&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;As I mentioned in my previous blog post, there are 2 methods to tackle the case when we have data from only one class:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The first method is an obvious approach to generate an artificial second class and proceed with traditional classification algorithms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second one is to modify the existing classification algoriths to learn on the data from only one class. These algorithms are called "one-class classfication algorithms" and include one-class SVM, One-Class K-Means, One-Class K-Nearest Neighbor, and One-Class Gaussian.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this blog entry, I will elaborate on the second method and explain the mathematics behind the one-class classification algorithms and how it improves over the traditional classification algorithms. &lt;/p&gt;
&lt;h3&gt;Fundamental difference between Binary and One Class Classification Algorithms&lt;/h3&gt;
&lt;p&gt;Binary classification algorithms are &lt;em&gt;discriminatory in nature&lt;/em&gt;, since they learn to discriminate between classes using all data classes to create a hyperplane(as seen in the fig. below) and use the hyperplane to label a new sample. In case of imbalance between the classes, the discriminatory methods can not be used to their full potential, since by their very nature, they rely on data from all classes to build the hyperplane that separate the various classes.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/binaryClassification.png" alt="Binary Classification Hyperplane" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;Binary Classification Hyperplane&lt;/center&gt;&lt;br&gt;
&lt;p&gt;Where as the one-class algorithms are based on &lt;em&gt;recognition&lt;/em&gt; since their aim is to recognize data from a particular class, and reject data from all other classes. This is accomplished by creating a boundary that encompasses all the data belonging to the target class within itself, so when a new sample arrives the algorithm only has to check whether it lies within the boundary or outside and accordingly classify the sample as belonging to the target class or the outlier.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/oneClassClassification.png" alt="One-Class Classification Boundary" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;One-Class Classification Boundary&lt;/center&gt;&lt;br&gt;
&lt;h3&gt;Mathematics behind different One-Class Classification Algorithms&lt;/h3&gt;
&lt;p&gt;In this section, I will explain the mathematics behind different one-class machine learning algorithms by taking a cue from &lt;a href="http://file.scirp.org/pdf/JBiSE20100300003_45072138.pdf"&gt;this research paper&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Gaussian&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;This is basically a density estimation model. It assumes that the training data are the samples from the &lt;em&gt;Multivariate Normal Population&lt;/em&gt;, therefore for a test sample (say z) having n-feaures, the probability of it belonging to the target class can be calculated as follows:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/one-classGaussian.png" alt="one-class gaussian" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the parameters μ and Σ are the &lt;em&gt;poputation mean and covariance&lt;/em&gt;. Hence, the objective function of this machine learning algorithm is to determine the estimates for μ and Σ. Using the &lt;strong&gt;method of maximum likelihood estimator&lt;/strong&gt;, we can show that the sample mean and sample covariance are the unbiased and consistent estimators for population mean and variance respectively. Hence, once we calculate the probability p(z), we can set a threshold to determine whether a new sample is outlier or not.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class Kmeans&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;In this method, we first classify the training data into k clusters (which is chosen as per our requirements). Then, for a new sample (say z), the distance &lt;em&gt;d(z)&lt;/em&gt; is calculated as the minimum distance of the sample from the centroid of all the k clusters. Now if &lt;em&gt;d(z)&lt;/em&gt; is less than a particular thereshold (which is again chosen as per our requirements), then the sample belongs to the target class otherwise it is classified as the outlier.&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;One-Class K-Nearest Neighbor&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Let us take note of some notation before we understand the mathematics behind the algorithm.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;d(z,y)&lt;/em&gt; : distance between two samples z and y&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NN(y)&lt;/em&gt; : Nearest Neighbor of sample y&lt;/p&gt;
&lt;p&gt;Now given a test sample z, we find the nearest neighbor of z from the training data (which is NN(z) = y) and the nearest neighbor of y (which is NN(y)). Now the rule is to classify z as belonging to the target class when:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/K-NearestNeighbor.png" alt="K-Nearest Neighbor" height="100px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;&lt;br&gt;
&lt;p&gt;where the default value of δ is 1 but can be chosen to satisfy our requirements.&lt;/p&gt;
&lt;p&gt;In my next blog entry, I will try to explain the most widely used one-class classification algorithm i.e. one-class support vector machines. Stay tuned !&lt;/p&gt;
&lt;p&gt;Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;

&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;

&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/div&gt;</description><category>Application of Novelty Detection Algorithms to predict Electricity Theft</category><category>Machine Learning</category><guid>http://Ayush-iitkgp.github.io/posts/one-class-classification-algorithms/</guid><pubDate>Sun, 22 Jan 2017 06:43:21 GMT</pubDate></item><item><title>When does traditional classification algorithm fail?</title><link>http://Ayush-iitkgp.github.io/posts/when-does-traditional-classification-algorithm-fail/</link><dc:creator>Ayush Pandey</dc:creator><description>&lt;div&gt;&lt;p&gt;One of the most intriguing Machine Learning problems that I have come across was during my 3rd year in the college where a startup named Quantta Analytics presented us with the problem statement about a power distribution company which had observed a significant loss of revenue over a period of time. The loss in revenue was mainly becuase of possible power theft by malicious consumers. The power company resorted to periodic vigilance of customers by sampling and &lt;strong&gt;creating a database of only the fraudulent customers&lt;/strong&gt; to curb this practice. The company wanted the vigilance process to be more robust and effective. Hence, the objective of the problem statement was to deploy a machine learning algorithm to provide a list of customers who are likely to commit fraud. So the problem was effectively a classification problem (&lt;strong&gt;with a catch!&lt;/strong&gt;) where given the attributes of a customer, we had to predict where it is likely to commit the electricity theft or not.&lt;/p&gt;
&lt;p&gt;In order to appreciate the problem statement, let us first have the review of the well-known famous classification algorithms. Classification problems try to solve the two or multi-class situation. The goal is to distinguish test data between a number of classes, using training data which has samples from all the possible classes and &lt;strong&gt;training data has reasonable level of balance between the various classes&lt;/strong&gt;. Now the question that arise is - &lt;em&gt;At what levels of imbalance does the use of traditional classifiers becomes futile?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://ieeexplore.ieee.org/document/6406735/"&gt;This paper&lt;/a&gt; has made observation by conducting experiments on various datasets from the UCI repository, and monitoring the performance of the traditional classifiers. I am listing down the most important observations stated in the paper:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The performance of the traditional classifiers start to decline when the imbalance between output classes increase and &lt;strong&gt;the decline becomes prominent at the ratio 1:2.8&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;At the ratio 1:10&lt;/strong&gt;, the performance is so poor for traditional classifiers that it can no longer be trusted.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Figure below shows the initial ratio of the classes present in UCI dataset and the ratio at which the performance of the binary classiﬁers starts to deteriorate.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/BinaryPerformanceTable.png" alt="Binary Classification Algorithm Performance Table" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;
&lt;p&gt;Now the questions that arise are - what if we have the training data which has imbalance between the classes or data only from one class? Why do we need to study such case? And are there any situations where such data is available?&lt;/p&gt;
&lt;p&gt;To answer the latter first, yes there are plenty of situations where we have the data from only one class. Consider a case of a nuclear power plant. We have the measurement of the plant conditions such as temperature, reaction rate when the plant is in working condition. Is it possible to get such measurements in case of an accident? No. Now, if we want to predict the possible scenario of the breakdown of the plant. From the above observations it is sure that the traditional classification algorithms will not perform well. Some other cases are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Detection of oil spill&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In computational biology to predict microRNA gene target&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are 2 methods to tackle the case when we have data from only one class:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The first method is an obvious approach to generate an artificial second class and proceed with traditional classification algorithms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second one is to modify the existing classification algoriths to learn on the data from only one class. These algorithms are called "one-class classfication algorithms" and include one-class SVM, One-Class K-Means, One-Class K-Nearest Neighbor, and One-Class Gaussian.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I will be elaborating on the above two methods in my next blog post. Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;

&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;

&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/div&gt;</description><category>Application of Novelty Detection Algorithms to predict Electricity Theft</category><category>Machine Learning</category><guid>http://Ayush-iitkgp.github.io/posts/when-does-traditional-classification-algorithm-fail/</guid><pubDate>Tue, 17 Jan 2017 06:43:21 GMT</pubDate></item><item><title>Is it the end or another beginning ?</title><link>http://Ayush-iitkgp.github.io/posts/is-it-the-end-or-another-beginning/</link><dc:creator>Ayush Pandey</dc:creator><description>&lt;div&gt;&lt;h3&gt;&lt;a href="http://nbviewer.jupyter.org/github/Ayush-iitkgp/GSoc-Proposal/blob/master/GSoC%202016%20Application%20Ayush%20Pandey-%20Support%20for%20complex%20numbers%20within%20Convex.jl.ipynb"&gt;Proposal&lt;/a&gt;            &lt;a href="https://ayush-iitkgp.github.io/categories/gsoc16/"&gt;Blog&lt;/a&gt;            &lt;a href="http://Ayush-iitkgp.github.io/stories/juliacon-2016-talk/"&gt;Talk&lt;/a&gt;            &lt;a href="https://drive.google.com/file/d/0B2oOdWdSJWa1cUFKTGI0czFDSDQ/view?usp=sharing"&gt;Presentation&lt;/a&gt;            &lt;a href="https://github.com/Ayush-iitkgp/Convex.jl/tree/gsoc2"&gt;Github&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;It hasn't been long when I was hugging my friends, calling my parents to inform them of my selection to Google Summer of Code, 2016 program and now here I am writing a wrap-up post for the program. I remember wanting to spend my summers working on the project that involved lots of mathematics, some of the computer science and travel as part of the project. I am so thankful to Google Summer of Code, 2016 program and The Julia Language to have made my each and every wish come true. The thanksgiving note would be incomplete without the mention of my mentors Madeleine and Dj who always helped me whenever I felt like giving up.&lt;/p&gt;
&lt;p&gt;Now, coming to the technical aspects of my project, it was divide in 3 phases based on the branches of convex programming namely:&lt;/p&gt;
&lt;h4&gt;1. Support for complex-domain linear programs&lt;/h4&gt;
&lt;p&gt;During this phase of the project, I extended the present implementation in Convex.jl to provide support for linear programs involving complex variables and the complex coefficients. The technical details of the implementation are described in the blog post &lt;a href="https://ayush-iitkgp.github.io/posts/announcing-support-for-complex-domain-linear-programs-in-convexjl/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;2. Support for second order conic programs&lt;/h4&gt;
&lt;p&gt;In this phase of the project, I in consulation with my mentors, rewrote many the second order cone atoms such as abs, norm to accept complex arguments. We also had an intense discussion on whether redefining the above atoms to accept complex arguments would violate DCP compliance and we came to a conclusion that defining inverse or the square atoms on complex variables neither makes sense nor does it preserve the DCP compliance.&lt;/p&gt;
&lt;h4&gt;3. Support for Complex Semidefinite programs&lt;/h4&gt;
&lt;p&gt;The above 2 phases were relatively difficult for us as we had no literature references and the decision we made were solely based on our understanding and intuition. During this phase, we used the mapping in the introductory section of the research paper &lt;a href="http://arxiv.org/pdf/1007.2905v2.pdf"&gt;here&lt;/a&gt; to transform a complex semidefinite program to the corresponding real semidefinite program. Presently, I am writing test cases to check the correctness of our implementation.&lt;/p&gt;
&lt;p&gt;The exhaustive list of commits can be found &lt;a href="https://github.com/Ayush-iitkgp/Convex.jl/commits/gsoc2"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I am glad to have been successfully implemented what I proposed. Presently, I am also writing the documentation and examples to demonstrate the usability of my implementation. The project will culminate with a single pull request to the Convex.jl repository as well as the release of a new version of Convex.jl which we plan to do in next few days. &lt;/p&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;p&gt;[1].&lt;a href="http://www.sciencedirect.com/science/article/pii/S0022000003001454"&gt;Approximation algorithms for MAX-3-CUT and other problems via complex semidefinite programming&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2].&lt;a href="http://arxiv.org/pdf/1007.2905v2.pdf"&gt;Invariant semidefinite programs&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3].&lt;a href="http://arxiv.org/pdf/1410.4821.pdf"&gt;Convex Optimization in Julia&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[4].&lt;a href="https://github.com/JuliaOpt/Convex.jl/issues/103"&gt;Support for complex variables&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[5].&lt;a href="https://github.com/cvxgrp/cvxpy/issues/191"&gt;Add complex variables&lt;/a&gt;&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;

&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;

&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/div&gt;</description><category>GSoC'16</category><guid>http://Ayush-iitkgp.github.io/posts/is-it-the-end-or-another-beginning/</guid><pubDate>Fri, 19 Aug 2016 20:43:21 GMT</pubDate></item><item><title>Announcing support for complex-domain linear Programs in Convex.jl</title><link>http://Ayush-iitkgp.github.io/posts/announcing-support-for-complex-domain-linear-programs-in-convexjl/</link><dc:creator>Ayush Pandey</dc:creator><description>&lt;div&gt;&lt;p&gt;I am pleased to announce the support for complex-domain linear Programs (LPs) in Convex.jl. As one of the &lt;em&gt;Google Summer of Code&lt;/em&gt; students under &lt;em&gt;The Julia Language&lt;/em&gt;, I had proposed to implement the support for complex semidefinite programming. In the first phase of project, I started by tackling the problem of complex-domain LPs where in first subphase, I had announced the support for complex coefficients during &lt;a href="https://www.youtube.com/watch?v=fHG4uEOlMbY"&gt;JuliaCon'16&lt;/a&gt; and now I take this opportunity to announce the support for complex variables in LPs.&lt;/p&gt;
&lt;p&gt;Complex-domain LPs consist of a real linear objective function, real linear inequality constraints, and real and complex linear equality constraints.&lt;/p&gt;
&lt;p&gt;In order to enable complex-domain LPs, we came up with these ideas:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We redefined the &lt;strong&gt;conic_form!&lt;/strong&gt; of every affine atom to accept complex arguments.&lt;/li&gt;
&lt;li&gt;Every complex variable z was internally represented as &lt;code&gt;z = z1 + i*z2&lt;/code&gt;, where z1 and z2 are real.&lt;/li&gt;
&lt;li&gt;We introduced two new affine atoms &lt;strong&gt;real&lt;/strong&gt; and &lt;strong&gt;imag&lt;/strong&gt; which return the real and the imaginary parts of the complex variable respectively.&lt;/li&gt;
&lt;li&gt;transpose and ctranspose perform differently on complex variables so a new atom &lt;strong&gt;CTransposeAtom&lt;/strong&gt; was created.&lt;/li&gt;
&lt;li&gt;A complex-equality constraint &lt;em&gt;RHS = LHS&lt;/em&gt; can be decomposed into two corresponding real equalities constraint &lt;em&gt;real(RHS) = real(LHS)&lt;/em&gt; and &lt;em&gt;imag(RHS) = imag(LHS)&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After above changes were made to the codebase, we wrote two use cases to demonstrate the usability and the correctness of our idea which I am presenting below:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;# Importing Packages
Pkg.clone("https://github.com/Ayush-iitkgp/Convex.jl/tree/gsoc2")
using Convex

# Complex LP with real variable"
n = 10 # variable dimension (parameter)
m = 5 # number of constraints (parameter)
xo = rand(n)
A = randn(m,n) + im*randn(m,n)
b = A * xo 
# Declare a real variable
x = Variable(n)
p1 = minimize(sum(x), A*x == b, x&amp;gt;=0) 
# Notice A*x==b is complex equality constraint 
solve!(p1)
x1 = x.value

# Let's now solve by decomposing complex equality constraint into the corresponding real and imaginary part.
p2 = minimize(sum(x), real(A)*x == real(b),      imag(A)*x==imag(b), x&amp;gt;=0)
solve!(p2)
x2 = x.value
x1==x2 # should return true


# Let's now take an example where the complex variable is used
# Complex LP with complex variable
n = 10 # variable dimension (parameter)
m = 5 # number of constraints (parameter)
xo = rand(n)+im*rand(n)
A = randn(m,n) + im*randn(m,n)
b = A * xo

# Declare a complex variable
x = ComplexVariable(n)
p1 = minimize(real(sum(x)), A*x == b, real(x)&amp;gt;=0, imag(x)&amp;gt;=0)
solve!(p1)
x1 = x.value

xr = Variable(n)
xi = Variable(n)
p2 = minimize(sum(xr), real(A)*xr-imag(A)*xi == real(b), imag(A)*xr+real(A)*xi == imag(b), xr&amp;gt;=0, xi&amp;gt;=0)
solve!(p2)
x1== xr.value + im*xi.value # should return true
&lt;/pre&gt;


&lt;p&gt;List of all the affine atoms are as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;addition, substraction, multiplication, division&lt;/li&gt;
&lt;li&gt;indexing and slicing&lt;/li&gt;
&lt;li&gt;k-th diagonal of a matrix&lt;/li&gt;
&lt;li&gt;construct diagonal matrix&lt;/li&gt;
&lt;li&gt;transpose and ctranspose&lt;/li&gt;
&lt;li&gt;stacking&lt;/li&gt;
&lt;li&gt;sum&lt;/li&gt;
&lt;li&gt;trace&lt;/li&gt;
&lt;li&gt;conv&lt;/li&gt;
&lt;li&gt;real and imag&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now, I am working towards implementing the complex-domain Second Order Conic Programming. Meanwhile, I invite the Julia community to play around with the complex-domain LPs. The link to the development branch is &lt;a href="https://github.com/Ayush-iitkgp/Convex.jl/tree/gsoc2"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Looking forward to your suggestions!&lt;/p&gt;
&lt;p&gt;Special thanks to my mentors Madeleine and Dj!&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;

&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;

&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/div&gt;</description><category>GSoC'16</category><guid>http://Ayush-iitkgp.github.io/posts/announcing-support-for-complex-domain-linear-programs-in-convexjl/</guid><pubDate>Tue, 26 Jul 2016 20:43:21 GMT</pubDate></item><item><title>A month of Excitement!</title><link>http://Ayush-iitkgp.github.io/posts/a-month-of-excitement/</link><dc:creator>Ayush Pandey</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;strong&gt;Every day is a new experience and it opening up new opportunities. Life is awesome&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;That is how I would describe my first month as GSoCer. From meeting new like minded people from all across the world to having an intense discussion about our projects in different groups to getting excited about receiving google goodies and now finally getting invited to JuliaCon'16 to be held at MIT, Cambridge, Massachusetts. Every experience has been worth the work put behind getting selected into GSoC'16.&lt;/p&gt;
&lt;p&gt;I got into coding my project and community bonding as soon as my exams got over on 29th April. Before I get into the details of my project, I would like to extend this opportunity to explain how my project is of importance to the optimization community in particular. The reason is as follows: &lt;/p&gt;
&lt;p&gt;Many problems in applied sciences are posed as optimization problems over the complex field such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Phase retrieval from sparse signals&lt;/li&gt;
&lt;li&gt;Designing an FIR filter given desired frequency response&lt;/li&gt;
&lt;li&gt;Optimization problems in AC power systems&lt;/li&gt;
&lt;li&gt;Frequency domain analysis in signal processing and control theory.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The present approach is to manually convert the complex-domain problems to real-domain problems &lt;a href="http://nbviewer.jupyter.org/github/cvxgrp/cvxpy/blob/master/examples/notebooks/WWW/fir_chebychev_design.ipynb"&gt;(example)&lt;/a&gt; and pass to solvers. This process can be time-consuming and non-intuitive sometimes. The correct approach to such problem would be to make existing packages deal with complex-domain optimization hence making it easier for the optimization community to deal with complex-domain problems.&lt;/p&gt;
&lt;p&gt;In the first hangout call with my mentors, we had decided to implement the functionality to support the Linear complex-domain optimization problem in Convex.jl. In order to support the above functionality, I was required to make the following changes:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Add support for complex variables, Hermitian SemiDefinite matrix and complex constants. This was done by introducing a new sign &lt;code&gt;ComplexSign&lt;/code&gt; which was introduced as the subtype of the user-defined type &lt;code&gt;Sign&lt;/code&gt; in dcp.jl file. I also went on to define the new rules for basic rules on interactions of mathematical expressions with the mathematical expression with &lt;code&gt;ComplexSign&lt;/code&gt;&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;abstract Sign
type Positive &amp;lt;: Sign                   end
type Negative &amp;lt;: Sign                   end
type NoSign &amp;lt;: Sign                     end
type ComplexSign &amp;lt;: Sign                end

-(s::ComplexSign) = ComplexSign()
+(s::ComplexSign, t::ComplexSign) = s
+(s::Sign, t::ComplexSign) = t
+(t::ComplexSign, s::Sign) = s+t
*(t::ComplexSign, s::ComplexSign) = t
*(t::ComplexSign, s::Sign) = t
*(s::Sign, t::ComplexSign) = t
*(s::ComplexSign, m::Monotonicity) = NoMonotonicity()
*(m::Monotonicity, s::Sign) = s * m
*(s::ComplexSign, v::ConstVexity) = v
*(s::ComplexSign, v::AffineVexity) = v
*(s::ComplexSign, v::ConvexVexity) = NotDcp()
*(s::ComplexSign, v::ConcaveVexity) = NotDcp()
*(s::ComplexSign, v::NotDcp) = v
&lt;/pre&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;As a result of changes made in point 1, I was able to modify the constant.jl and variable.jl file accordingly.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nx"&gt;ComplexVariable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;m&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nx"&gt;Int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;n&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nx"&gt;Int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;sets&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nx"&gt;Symbol&lt;/span&gt;&lt;span class="p"&gt;...)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nx"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;n&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nx"&gt;ComplexSign&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="nx"&gt;sets&lt;/span&gt;&lt;span class="p"&gt;...)&lt;/span&gt;
&lt;span class="nx"&gt;ComplexVariable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;sets&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nx"&gt;Symbol&lt;/span&gt;&lt;span class="p"&gt;...)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nx"&gt;ComplexSign&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="nx"&gt;sets&lt;/span&gt;&lt;span class="p"&gt;...)&lt;/span&gt;
&lt;span class="nx"&gt;ComplexVariable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;size&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nx"&gt;Tuple&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;Int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;Int&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="nx"&gt;sets&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nx"&gt;Symbol&lt;/span&gt;&lt;span class="p"&gt;...)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;ComplexSign&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="nx"&gt;sets&lt;/span&gt;&lt;span class="p"&gt;...)&lt;/span&gt;
&lt;span class="nx"&gt;ComplexVariable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;size&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nx"&gt;Int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;sets&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nx"&gt;Symbol&lt;/span&gt;&lt;span class="p"&gt;...)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nx"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nx"&gt;ComplexSign&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="nx"&gt;sets&lt;/span&gt;&lt;span class="p"&gt;...)&lt;/span&gt;
&lt;span class="nx"&gt;HermitianSemidefinite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;m&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nx"&gt;Integer&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;ComplexVariable&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nx"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;m&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="nx"&gt;Semidefinite&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;HermitianSemidefinite&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;m&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nx"&gt;Integer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;n&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nx"&gt;Integer&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nx"&gt;m&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="nx"&gt;n&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;ComplexVariable&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nx"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nx"&gt;m&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="nx"&gt;Semidefinite&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;else&lt;/span&gt;
    &lt;span class="nx"&gt;error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"HermitianSemidefinite matrices must be square"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nx"&gt;end&lt;/span&gt;
&lt;span class="nx"&gt;end&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;Now, the user can create the complex variables, Hermitian-semidefinite matrix in Convex.jl as follows:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;y = ComplexVariable()
Variable of
size: (1, 1)
sign: Convex.ComplexSign()
vexity: Convex.AffineVexity()
z = HermitianSemidefinite(4)
Variable of
size: (4, 4)
sign: Convex.ComplexSign()
vexity: Convex.AffineVexity()
&lt;/pre&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The third step was to redefine the &lt;a href="https://github.com/Ayush-iitkgp/Convex.jl/tree/gsoc1/src/atoms/affine"&gt;affine&lt;/a&gt; atoms in Convex.jl to accommodate the complex variable case as well. Interestingly, by virtue of the rules defined in step 1 in dcp.jl, we didn't even need to define any affine atom to accommodate the complex case, Convex.jl is smart enough to pick the sign of the expression using rules in dcp.jl. &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So this was the summary of what I have been doing on the coding side of GSoC. On the other side, I moved to Bangalore (India's Silicon Valley) where I would be spending next two months and I am very excited to meet the other JuliaSoCers at the Julia Computing Bangalore office in the days to come.&lt;/p&gt;
&lt;p&gt;Also, the coming week is crucial for us as we have decided to fully implement the complex-domain Linear Programming Problem in Convex.jl. Last night, we had our 3rd hangout meeting where we discussed the nitty-gritty of Convex.jl especially the conic form functionality and how to proceed so as to meet the deadline that we have set up for ourselves. I look forward to another week of coding and making new friends and getting involved in the Open Source Community.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Bragging Rights- Convex.jl would be the second optimization package after Matlab's cvx to support complex-domain optimization problems, so yes this excites me as well to be a part the team that is developing such a useful package.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Also, I am very very much excited to attend JuliaCon'16 at the Massachusetts Institute of Technology and give a talk on what I have been doing this summer. I hope I get the visa on time, wish me luck everyone :)&lt;/p&gt;
&lt;p&gt;See you next time till then keep laughing, spreading happiness and the most importantly living this journey called life!!!! &lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;

&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;

&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/div&gt;</description><category>GSoC'16</category><guid>http://Ayush-iitkgp.github.io/posts/a-month-of-excitement/</guid><pubDate>Sun, 22 May 2016 16:14:47 GMT</pubDate></item><item><title>Exciting Summers Ahead!</title><link>http://Ayush-iitkgp.github.io/posts/exciting-summers-ahead/</link><dc:creator>Ayush Pandey</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;strong&gt;Fall seven times, stand up eight !!!!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Google Summer of Code, the thing I wanted to be a part of as soon as I heard of it in my 1st year of college. It took me 4 years when I am finally selected for the prestigious open source program. Harsh Gupta no word can express my gratefulness for you. Thank you very much for always being there. Coincidently, the results were announced in the middle of my end-semester examination and I must accept my selection was one more reason for not studying for the exams. I am glad that my exams are over and as always I am looking forward to the summers where I apply the theories I have learnt during the semester in a practical world. I think I should make it apparent that applying to Julia and getting selected was a well-thought process, there were series of events which helped me getting selected in GSoC under The Julia Lang. It all started when I was finishing the web-development internship during the winter vacations when I realized that I need to pursue applied mathematics more seriously as that is somewhere I can excel at. &lt;strong&gt;Operations Research and Optimization&lt;/strong&gt; was an obvious choice as I enjoyed the introductory course in Linear Programming way more than other cs and mathematics courses that I took during my stay at IIT Kharagpur. I decided to take an advanced course in Optimization(Non-Linear Programming) but sadly the course was open for final year students but yes &lt;em&gt;where there is will, there is a way&lt;/em&gt;, I was able to enroll for the course after consulting with my professor, interestingly I was the only pre-final year student in that class yet I tried to attend each and every class in spite of not having familiar faces to sit with. During the semester, 4th InterIIT Meet was being held at IIT Mandi. Initially, I was not the part of IIT Kharagpur's contingent as I didn't find myself competent enough to apply for the selections. But as soon as the problem statement for the event Portfolio Optimization was out, my friend Raja Ambrish contacted me as the problem was related to Convex Optimization because he thought I could help him. My eyes were lit bright as soon as I saw the problem statement as it was the application of what I have been reading throughout the semester. I worked with the other team members and was finally selected to present our solution to the jury at IIT Mandi. Yay, IIT Kharagpur were the overall champions and also our team managed to win gold medal Portfolio Optimization as well.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/InterIITTech.jpg" alt="A click during InterIIT Presentation" height="400px" width="750px" border="1px" style="margin: 0px 20px"&gt;&lt;/p&gt;
&lt;p&gt;The InterIIT experience was awesome and it made me realize that indeed I have a special interest in the field of Optimization. I wanted to explore more of this field and Google Summer of Code was an exciting opportunity. I told my friend Harsh about the plans to participate in GSoC in an organization which has Optimization related projects and his first suggestion was &lt;a href="http://julialang.org/"&gt;Julia&lt;/a&gt;. I came back room and browsed projects and wow Julia has this one project namely &lt;code&gt;"Support for Complex SemiDefinite Programming within Convex.jl"&lt;/code&gt; on Convex Optimization that I fell in love with. The concepts I learnt during the classroom hours in Non-Linear Programming were of immense help to me in getting started with Convex.jl special thanks to Prof. Geetanjali Panda for teaching this course in a very intuitive way.&lt;/p&gt;
&lt;p&gt;Finally, after having an extensive discussion with my mentors &lt;a href="https://people.orie.cornell.edu/mru8/"&gt;Madeleine Udell&lt;/a&gt; and &lt;a href="http://www.its.caltech.edu/~dvij/"&gt;Dvijotham Krishnamurthy&lt;/a&gt;, I submitted my &lt;a href="http://nbviewer.jupyter.org/github/Ayush-iitkgp/GSoc-Proposal/blob/master/GSoC%202016%20Application%20Ayush%20Pandey-%20Support%20for%20complex%20numbers%20within%20Convex.jl.ipynb"&gt;proposal&lt;/a&gt; under The Julia Lang and NumFocus and was selected under former. I want to express my gratefulness to each and everyone who has helped me before and throughout the GSoC Application Period.&lt;/p&gt;
&lt;p&gt;I am officially in the first week of the Community Bonding Period. My week started with having a video call with my mentors where we discussed my proposal in more detail and went through some of the existing codebase in order to understand what specific changes need to be made to accomplish our task. We have started by first tackling the complex-domain Linear Programming Problems. We have decided that we would need few utility functions like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A function to recurse on the expression tree to check if an expression is real or complex&lt;/li&gt;
&lt;li&gt;A function conj(A)&lt;/li&gt;
&lt;li&gt;A function to check the LHS and RHS of each inequality constraint is real.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I would also need to think of the rules that would be helpful in determining whether the combination of two or more expressions is real or complex on the lines of how we determine the DCP compliance of a problem. The next step would be to rewrite all the atoms to accept the complex parameters.&lt;/p&gt;
&lt;p&gt;The next assignment was to set-up a blog to write and publish my experience as GSoCer or rather JuliaSoCer which I did just complete :D During this week, I was also introduced to the Julia community and added to their slack channel. I believe I would have some awesome time with the community and hope to see them during JuliaCon 2016.&lt;/p&gt;
&lt;p&gt;Interestingly, I have my birthday on 4th May which I plan to celebrate with my family so I would be traveling to my home from my university. Don't forget to wish me ;) &lt;/p&gt;
&lt;p&gt;This is all for now. Thank you very much for making it this far :)&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;

&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;

&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/div&gt;</description><category>GSoC'16</category><guid>http://Ayush-iitkgp.github.io/posts/exciting-summers-ahead/</guid><pubDate>Tue, 03 May 2016 16:08:08 GMT</pubDate></item><item><title>Novelty Detection Algorithms</title><link>http://Ayush-iitkgp.github.io/posts/novelty-detection-algorithms/</link><dc:creator>Ayush Pandey</dc:creator><description>&lt;div&gt;&lt;p&gt;One of the most intriguing Machine Learning problems that I have come across was during my 3rd year in the college where a startup named Quantta Analytics presented us with the problem statement about a power distribution company which had observed a significant loss of revenue over a period of time. The loss in revenue was mainly becuase of possible power theft by malicious consumers. The power company resorted to periodic vigilance of customers by sampling and &lt;strong&gt;creating a database of only the fraudulent customers&lt;/strong&gt; to curb this practice. The company wanted the vigilance process to be more robust and effective. Hence, the objective of the problem statement was to deploy a machine learning algorithm to provide a list of customers who are likely to commit fraud. So the problem was effectively a classification problem (&lt;strong&gt;with a catch&lt;/strong&gt;) where given the attributes of a customer we had to predict where it would commit the electricity theft or not.&lt;/p&gt;
&lt;p&gt;In order to appreciate the problem statement, let us first have the review of the well-known famous classification algorithms. Classification problems try to solve the two or multi-class situation. The goal is to distinguish test data between a number of classes, using training data which has samples from all the possible classes and &lt;strong&gt;training data has reasonable level of balance between the various classes&lt;/strong&gt;. Now the question that arise is - &lt;em&gt;At what levels of imbalance does the use of traditional classifiers becomes futile?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://ieeexplore.ieee.org/document/6406735/"&gt;This paper&lt;/a&gt; has made observation by conducting experiments on various datasets from the UCI repository, and monitoring the performance of the traditional classifiers. I am listing down the most important observations stated in the paper:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The performance of the traditional classifiers start to decline when the imbalance between output classes increase and &lt;strong&gt;the decline becomes prominent at the ratio 1:2.8&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;At the ratio 1:10&lt;/strong&gt;, the performance is so poor for traditional classifiers that it can no longer be trusted.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Figure below shows the initial ratio of the classes present in UCI dataset and the ratio at which the performance of the binary classiﬁers starts to deteriorate.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;center&gt;&lt;img src="http://Ayush-iitkgp.github.io/images/BinaryPerformanceTable.png" alt="Binary Classification Algorithm Performance Table" height="200px" width="375px" border="1px" style="margin: 0px 20px"&gt;&lt;/center&gt;
&lt;p&gt;Now the questions that arise are - what if we have the training data which has imbalance between the classes or data only from one class? Why do we need to study such case? And are there any situations where such data is available?&lt;/p&gt;
&lt;p&gt;To answer the latter first, yes there are plenty of situations where we have the data from only one class. Consider a case of a nuclear power plant. We have the measurement of the plant conditions such as temperature, reaction rate when the plant is in working condition. Is it possible to get such measurements in case of an accident? No. Now, if we want to predict the possible scenario of the breakdown of the plant. From the above observations it is sure that the traditional classification algorithms will not perform well. Some other cases are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Detection of oil spill&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In computational biology to predict microRNA gene target&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are 2 methods to tackle the case when we have data from only one class:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The first method is an obvious approach to generate an artificial second class and proceed with traditional classification algorithms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second one is to modify the existing classification algoriths to learn on the data from only one class. These algorithms are called "one-class classfication algorithms" and include one-class SVM, One-Class K-Means, One-Class K-Nearest Neighbor, and One-Class Gaussian.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I will be elaborating on the above two methods in my next blog post. Thank you very much for making it this far.&lt;/p&gt;
&lt;div id="disqus_thread"&gt;&lt;/div&gt;

&lt;script&gt;
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//avoyage.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;

&lt;noscript&gt;Please enable JavaScript to view the &lt;a href="https://disqus.com/?ref_noscript" rel="nofollow"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/div&gt;</description><guid>http://Ayush-iitkgp.github.io/posts/novelty-detection-algorithms/</guid><pubDate>Sun, 20 Apr 2014 06:43:21 GMT</pubDate></item></channel></rss>